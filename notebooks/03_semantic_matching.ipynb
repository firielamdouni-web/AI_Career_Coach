{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b2481",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ðŸŽ¯ Notebook 03 : Matching SÃ©mantique avec Sentence-Transformers\n",
    "\n",
    "**Objectif** : Comparer des compÃ©tences par similaritÃ© sÃ©mantique (pas juste mots exacts)\n",
    "\n",
    "**MÃ©thode** :\n",
    "1. Charger un modÃ¨le de vectorisation (all-mpnet-base-v2)\n",
    "2. Transformer textes en vecteurs (embeddings)\n",
    "3. Calculer similaritÃ© cosinus entre vecteurs\n",
    "\n",
    "**Exemple** :\n",
    "- \"docker\" vs \"containerization\" â†’ 78% similaire âœ…\n",
    "- \"python\" vs \"programming\" â†’ 72% similaire âœ…\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeee1090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Projet : c:\\Users\\rober\\OneDrive\\Bureau\\PFE\n",
      "ðŸ“‚ Notebooks : c:\\Users\\rober\\OneDrive\\Bureau\\PFE\\notebooks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rober\\OneDrive\\Bureau\\PFE\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… sentence-transformers importÃ©\n",
      "âœ… scikit-learn importÃ©\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "\n",
    "# Ajouter le dossier racine\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"ðŸ“ Projet : {project_root}\")\n",
    "print(f\"ðŸ“‚ Notebooks : {Path().absolute()}\")\n",
    "\n",
    "# Importer Sentence-Transformers\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    print(\"âœ… sentence-transformers importÃ©\")\n",
    "    print(\"âœ… scikit-learn importÃ©\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Erreur d'import : {e}\")\n",
    "    print(\"âš ï¸  ExÃ©cutez : pip install sentence-transformers scikit-learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cd0a200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Chargement du modÃ¨le all-mpnet-base-v2...\n",
      "â³ PremiÃ¨re utilisation : tÃ©lÃ©chargement ~420 MB (1-2 min)\n",
      "âœ… ModÃ¨le chargÃ© avec succÃ¨s\n",
      "   â€¢ Nom : all-mpnet-base-v2\n",
      "   â€¢ Dimension des vecteurs : 768\n",
      "   â€¢ Langue : Anglais (optimisÃ©)\n",
      "   â€¢ Performance : State-of-the-art pour matching sÃ©mantique\n"
     ]
    }
   ],
   "source": [
    "# Charger le modÃ¨le de Sentence-Transformers\n",
    "print(\"\\nðŸ” Chargement du modÃ¨le all-mpnet-base-v2...\")\n",
    "print(\"â³ PremiÃ¨re utilisation : tÃ©lÃ©chargement ~420 MB (1-2 min)\")\n",
    "\n",
    "try:\n",
    "    model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    print(\"âœ… ModÃ¨le chargÃ© avec succÃ¨s\")\n",
    "    print(f\"   â€¢ Nom : all-mpnet-base-v2\")\n",
    "    print(f\"   â€¢ Dimension des vecteurs : 768\")\n",
    "    print(f\"   â€¢ Langue : Anglais (optimisÃ©)\")\n",
    "    print(f\"   â€¢ Performance : State-of-the-art pour matching sÃ©mantique\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f5c20aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST 1 : SimilaritÃ© entre mots techniques\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š RÃ©sultats :\n",
      "------------------------------------------------------------\n",
      "ðŸŸ¡ 'docker' â†” 'containerization' : 68.4%\n",
      "ðŸŸ¡ 'python' â†” 'programming' : 65.6%\n",
      "ðŸ”´ 'machine learning' â†” 'ml' : 49.7%\n",
      "ðŸ”´ 'react' â†” 'frontend framework' : 26.3%\n",
      "ðŸŸ¢ 'sql' â†” 'database' : 73.7%\n",
      "ðŸŸ¡ 'git' â†” 'version control' : 69.2%\n",
      "ðŸ”´ 'kubernetes' â†” 'orchestration' : 25.9%\n",
      "ðŸŸ¡ 'javascript' â†” 'web development' : 58.8%\n"
     ]
    }
   ],
   "source": [
    "# Test 1 : SimilaritÃ© entre deux mots techniques\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ§ª TEST 1 : SimilaritÃ© entre mots techniques\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# DÃ©finir les paires Ã  tester\n",
    "test_pairs = [\n",
    "    (\"docker\", \"containerization\"),\n",
    "    (\"python\", \"programming\"),\n",
    "    (\"machine learning\", \"ml\"),\n",
    "    (\"react\", \"frontend framework\"),\n",
    "    (\"sql\", \"database\"),\n",
    "    (\"git\", \"version control\"),\n",
    "    (\"kubernetes\", \"orchestration\"),\n",
    "    (\"javascript\", \"web development\"),\n",
    "]\n",
    "\n",
    "print(\"\\nðŸ“Š RÃ©sultats :\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for word1, word2 in test_pairs:\n",
    "    # Vectoriser les deux mots\n",
    "    embedding1 = model.encode([word1])\n",
    "    embedding2 = model.encode([word2])\n",
    "    \n",
    "    # Calculer similaritÃ© cosinus\n",
    "    similarity = cosine_similarity(embedding1, embedding2)[0][0]\n",
    "    similarity_percent = similarity * 100\n",
    "    \n",
    "    # Afficher avec emojis\n",
    "    if similarity_percent >= 70:\n",
    "        emoji = \"ðŸŸ¢\"\n",
    "    elif similarity_percent >= 50:\n",
    "        emoji = \"ðŸŸ¡\"\n",
    "    else:\n",
    "        emoji = \"ðŸ”´\"\n",
    "    \n",
    "    print(f\"{emoji} '{word1}' â†” '{word2}' : {similarity_percent:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dde818f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST 2 : Comparaison Mots Seuls vs Phrases\n",
      "============================================================\n",
      "\n",
      "1ï¸âƒ£ MOTS SEULS :\n",
      "   'machine learning' â†” 'ml'\n",
      "   SimilaritÃ© : 49.7%\n",
      "\n",
      "2ï¸âƒ£ PHRASES COMPLÃˆTES :\n",
      "   'I have experience in machine learning'\n",
      "   'I am an ML engineer'\n",
      "   SimilaritÃ© : 72.1%\n",
      "\n",
      "3ï¸âƒ£ CONTEXTE TECHNIQUE :\n",
      "   'machine learning models and algorithms'\n",
      "   'ml and deep learning'\n",
      "   SimilaritÃ© : 54.1%\n",
      "\n",
      "ðŸ“Š RÃ‰CAPITULATIF :\n",
      "   Mots seuls      : 49.7% âŒ\n",
      "   Phrases         : 72.1% âœ…\n",
      "   Contexte tech   : 54.1% âœ…\n"
     ]
    }
   ],
   "source": [
    "# Test : Mots seuls vs Phrases complÃ¨tes\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ§ª TEST 2 : Comparaison Mots Seuls vs Phrases\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test avec mots SEULS (actuel)\n",
    "word1 = \"machine learning\"\n",
    "word2 = \"ml\"\n",
    "\n",
    "embedding1 = model.encode([word1])\n",
    "embedding2 = model.encode([word2])\n",
    "similarity_words = cosine_similarity(embedding1, embedding2)[0][0] * 100\n",
    "\n",
    "print(f\"\\n1ï¸âƒ£ MOTS SEULS :\")\n",
    "print(f\"   '{word1}' â†” '{word2}'\")\n",
    "print(f\"   SimilaritÃ© : {similarity_words:.1f}%\")\n",
    "\n",
    "# Test avec PHRASES\n",
    "sentence1 = \"I have experience in machine learning\"\n",
    "sentence2 = \"I am an ML engineer\"\n",
    "\n",
    "embedding1 = model.encode([sentence1])\n",
    "embedding2 = model.encode([sentence2])\n",
    "similarity_sentences = cosine_similarity(embedding1, embedding2)[0][0] * 100\n",
    "\n",
    "print(f\"\\n2ï¸âƒ£ PHRASES COMPLÃˆTES :\")\n",
    "print(f\"   '{sentence1}'\")\n",
    "print(f\"   '{sentence2}'\")\n",
    "print(f\"   SimilaritÃ© : {similarity_sentences:.1f}%\")\n",
    "\n",
    "# Test avec CONTEXTE TECHNIQUE\n",
    "tech1 = \"machine learning models and algorithms\"\n",
    "tech2 = \"ml and deep learning\"\n",
    "\n",
    "embedding1 = model.encode([tech1])\n",
    "embedding2 = model.encode([tech2])\n",
    "similarity_tech = cosine_similarity(embedding1, embedding2)[0][0] * 100\n",
    "\n",
    "print(f\"\\n3ï¸âƒ£ CONTEXTE TECHNIQUE :\")\n",
    "print(f\"   '{tech1}'\")\n",
    "print(f\"   '{tech2}'\")\n",
    "print(f\"   SimilaritÃ© : {similarity_tech:.1f}%\")\n",
    "\n",
    "print(f\"\\nðŸ“Š RÃ‰CAPITULATIF :\")\n",
    "print(f\"   Mots seuls      : {similarity_words:.1f}% âŒ\")\n",
    "print(f\"   Phrases         : {similarity_sentences:.1f}% âœ…\")\n",
    "print(f\"   Contexte tech   : {similarity_tech:.1f}% âœ…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07c349a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ§ª TEST 3 : Matching CV vs Description de Poste\n",
      "============================================================\n",
      "âœ… CV chargÃ© : 3195 caractÃ¨res\n",
      "âœ… CompÃ©tences chargÃ©es : 24 compÃ©tences\n",
      "   Exemples : .net, artificial intelligence, big data, c, c#\n"
     ]
    }
   ],
   "source": [
    "# Charger le CV et les compÃ©tences trouvÃ©es\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ§ª TEST 3 : Matching CV vs Description de Poste\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Charger le texte du CV\n",
    "cv_text_path = Path().absolute() / \"cv_text_pdfplumber.txt\"\n",
    "\n",
    "if cv_text_path.exists():\n",
    "    with open(cv_text_path, 'r', encoding='utf-8') as f:\n",
    "        cv_text = f.read()\n",
    "    print(f\"âœ… CV chargÃ© : {len(cv_text)} caractÃ¨res\")\n",
    "else:\n",
    "    print(\"âŒ Fichier CV non trouvÃ©\")\n",
    "    cv_text = \"\"\n",
    "\n",
    "# Charger les compÃ©tences extraites\n",
    "output_path = project_root / \"outputs\" / \"extracted_skills_simple.json\"\n",
    "\n",
    "if output_path.exists():\n",
    "    with open(output_path, 'r', encoding='utf-8') as f:\n",
    "        extracted_data = json.load(f)\n",
    "    \n",
    "    cv_skills = extracted_data['technical_skills']\n",
    "    print(f\"âœ… CompÃ©tences chargÃ©es : {len(cv_skills)} compÃ©tences\")\n",
    "    print(f\"   Exemples : {', '.join(cv_skills[:5])}\")\n",
    "else:\n",
    "    print(\"âŒ Fichier compÃ©tences non trouvÃ©\")\n",
    "    cv_skills = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5d6f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrÃ©er une description de poste fictive\n",
    "job_description = \"\"\"\n",
    "We are looking for a Senior ML Engineer with strong experience in:\n",
    "- Deep Learning and Neural Networks\n",
    "- Python development with PyTorch or TensorFlow\n",
    "- Containerization (Docker, Kubernetes)\n",
    "- Cloud platforms (AWS, Azure, or GCP)\n",
    "- Data pipelines and ETL processes\n",
    "- RESTful API development\n",
    "- Version control with Git\n",
    "- Agile methodologies\n",
    "\n",
    "Nice to have:\n",
    "- Computer Vision or NLP experience\n",
    "- FastAPI or Flask\n",
    "- CI/CD pipelines\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60d54fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Calcul du matching CV â†” Offre d'emploi (VERSION AMÃ‰LIORÃ‰E)...\n",
      "   Analyse de 13 phrases dans la description...\n",
      "\n",
      "âœ… Analyse terminÃ©e\n",
      "   â€¢ Score global : 37.0%\n",
      "   â€¢ CompÃ©tences trÃ¨s pertinentes : 7/24\n"
     ]
    }
   ],
   "source": [
    "# Fonction de calcul de matching AMÃ‰LIORÃ‰E\n",
    "def calculate_cv_job_match(cv_skills: List[str], job_description: str, model) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculer le score de matching entre CV et offre d'emploi (VERSION 2)\n",
    "    \n",
    "    AmÃ©lioration : Compare chaque compÃ©tence avec chaque phrase de la description\n",
    "    au lieu de la description complÃ¨te (Ã©vite la dilution du vecteur)\n",
    "    \n",
    "    Args:\n",
    "        cv_skills: Liste de compÃ©tences du CV\n",
    "        job_description: Description du poste\n",
    "        model: ModÃ¨le Sentence-Transformer\n",
    "        \n",
    "    Returns:\n",
    "        Dict avec score global et dÃ©tails par compÃ©tence\n",
    "    \"\"\"\n",
    "    # DÃ©couper la description en lignes/phrases pertinentes\n",
    "    job_sentences = [\n",
    "        s.strip() \n",
    "        for s in job_description.split('\\n') \n",
    "        if s.strip() and len(s.strip()) > 10  # Ignorer lignes vides/courtes\n",
    "    ]\n",
    "    \n",
    "    print(f\"   Analyse de {len(job_sentences)} phrases dans la description...\")\n",
    "    \n",
    "    # Vectoriser toutes les phrases\n",
    "    job_embeddings = model.encode(job_sentences)\n",
    "    \n",
    "    # Analyser chaque compÃ©tence\n",
    "    matches = []\n",
    "    \n",
    "    for skill in cv_skills:\n",
    "        skill_embedding = model.encode([skill.lower()])\n",
    "        \n",
    "        # Calculer similaritÃ© avec CHAQUE phrase\n",
    "        similarities = cosine_similarity(skill_embedding, job_embeddings)[0]\n",
    "        \n",
    "        # Prendre la MEILLEURE similaritÃ© (max)\n",
    "        max_similarity = max(similarities) * 100\n",
    "        \n",
    "        # Trouver quelle phrase matche le mieux\n",
    "        best_match_idx = similarities.argmax()\n",
    "        best_sentence = job_sentences[best_match_idx]\n",
    "        \n",
    "        matches.append({\n",
    "            'skill': skill,\n",
    "            'similarity': max_similarity,\n",
    "            'match': 'high' if max_similarity >= 40 else 'medium' if max_similarity >= 30 else 'low',\n",
    "            'matched_sentence': best_sentence[:60] + '...' if len(best_sentence) > 60 else best_sentence\n",
    "        })\n",
    "    \n",
    "    # Trier par similaritÃ© dÃ©croissante\n",
    "    matches = sorted(matches, key=lambda x: x['similarity'], reverse=True)\n",
    "    \n",
    "    # Calculer score global\n",
    "    if matches:\n",
    "        avg_similarity = sum(m['similarity'] for m in matches) / len(matches)\n",
    "        high_matches = len([m for m in matches if m['match'] == 'high'])\n",
    "    else:\n",
    "        avg_similarity = 0\n",
    "        high_matches = 0\n",
    "    \n",
    "    return {\n",
    "        'overall_score': avg_similarity,\n",
    "        'high_matches': high_matches,\n",
    "        'total_skills': len(cv_skills),\n",
    "        'matches': matches\n",
    "    }\n",
    "\n",
    "\n",
    "# Calculer le matching avec la nouvelle version\n",
    "print(\"\\nðŸ” Calcul du matching CV â†” Offre d'emploi (VERSION AMÃ‰LIORÃ‰E)...\")\n",
    "\n",
    "if cv_skills:\n",
    "    result = calculate_cv_job_match(cv_skills, job_description, model)\n",
    "    \n",
    "    print(f\"\\nâœ… Analyse terminÃ©e\")\n",
    "    print(f\"   â€¢ Score global : {result['overall_score']:.1f}%\")\n",
    "    print(f\"   â€¢ CompÃ©tences trÃ¨s pertinentes : {result['high_matches']}/{result['total_skills']}\")\n",
    "else:\n",
    "    print(\"âŒ Aucune compÃ©tence Ã  analyser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "45faec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸŽ¯ MATCHING CV â†” OFFRE D'EMPLOI\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š SCORE GLOBAL : 37.0%\n",
      "ðŸŸ¡ BON MATCH - Candidat qualifiÃ©\n",
      "\n",
      "ðŸ”§ TOP 10 COMPÃ‰TENCES PERTINENTES :\n",
      "------------------------------------------------------------\n",
      " 1. ðŸŸ¢ git                       â†’ 69.9%\n",
      " 2. ðŸŸ¢ deep learning             â†’ 66.6%\n",
      " 3. ðŸŸ¢ docker                    â†’ 64.4%\n",
      " 4. ðŸŸ¢ machine learning          â†’ 51.5%\n",
      " 5. ðŸŸ¢ artificial intelligence   â†’ 44.8%\n",
      " 6. ðŸŸ¢ data science              â†’ 42.6%\n",
      " 7. ðŸŸ¢ jupyter                   â†’ 41.4%\n",
      " 8. ðŸŸ¡ scikit-learn              â†’ 38.0%\n",
      " 9. ðŸŸ¡ numpy                     â†’ 36.8%\n",
      "10. ðŸŸ¡ big data                  â†’ 36.4%\n",
      "11. ðŸŸ¡ python                    â†’ 35.0%\n",
      "12. ðŸŸ¡ linux                     â†’ 33.5%\n",
      "13. ðŸŸ¡ c++                       â†’ 31.1%\n",
      "14. ðŸŸ¡ sql                       â†’ 31.0%\n",
      "15. ðŸŸ¡ node.js                   â†’ 30.9%\n",
      "16. ðŸŸ¡ data analysis             â†’ 30.9%\n",
      "17. ðŸ”´ java                      â†’ 29.6%\n",
      "18. ðŸ”´ c#                        â†’ 27.5%\n",
      "19. ðŸ”´ .net                      â†’ 26.6%\n",
      "20. ðŸ”´ pandas                    â†’ 26.2%\n",
      "\n",
      "ðŸ’¡ CompÃ©tences trÃ¨s pertinentes (7) :\n",
      "  â€¢ git\n",
      "  â€¢ deep learning\n",
      "  â€¢ docker\n",
      "  â€¢ machine learning\n",
      "  â€¢ artificial intelligence\n"
     ]
    }
   ],
   "source": [
    "# Afficher les rÃ©sultats dÃ©taillÃ©s\n",
    "if 'result' in locals() and result['matches']:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸŽ¯ MATCHING CV â†” OFFRE D'EMPLOI\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š SCORE GLOBAL : {result['overall_score']:.1f}%\")\n",
    "    \n",
    "    if result['overall_score'] >= 40:\n",
    "        print(\"âœ… EXCELLENT MATCH - Candidat trÃ¨s qualifiÃ©\")\n",
    "    elif result['overall_score'] >= 30:\n",
    "        print(\"ðŸŸ¡ BON MATCH - Candidat qualifiÃ©\")\n",
    "    else:\n",
    "        print(\"ðŸ”´ MATCH FAIBLE - Profil diffÃ©rent\")\n",
    "    \n",
    "    print(f\"\\nðŸ”§ TOP 10 COMPÃ‰TENCES PERTINENTES :\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for i, match in enumerate(result['matches'][:20], 1):\n",
    "        emoji = \"ðŸŸ¢\" if match['match'] == 'high' else \"ðŸŸ¡\" if match['match'] == 'medium' else \"ðŸ”´\"\n",
    "        print(f\"{i:2d}. {emoji} {match['skill']:25s} â†’ {match['similarity']:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¡ CompÃ©tences trÃ¨s pertinentes ({result['high_matches']}) :\")\n",
    "    high_match_skills = [m['skill'] for m in result['matches'] if m['match'] == 'high']\n",
    "    for skill in high_match_skills[:5]:\n",
    "        print(f\"  â€¢ {skill}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7b6b7195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’¾ RÃ©sultats sauvegardÃ©s : c:\\Users\\rober\\OneDrive\\Bureau\\PFE\\outputs\\semantic_matching_results.json\n",
      "ðŸ“Š Taille : 4.4 KB\n",
      "\n",
      "âœ… Analyse sÃ©mantique terminÃ©e avec succÃ¨s !\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder les rÃ©sultats du matching\n",
    "if 'result' in locals():\n",
    "    output_dir = project_root / \"outputs\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    output_path = output_dir / \"semantic_matching_results.json\"\n",
    "    \n",
    "    # PrÃ©parer les donnÃ©es Ã  sauvegarder\n",
    "    save_data = {\n",
    "        \"cv_file\": \"RESUME ROBERT UNG.pdf\",\n",
    "        \"analysis_date\": \"2026-01-25\",\n",
    "        \"model\": \"all-mpnet-base-v2\",\n",
    "        \"overall_score\": round(float(result['overall_score']), 2),\n",
    "        \"high_matches\": int(result['high_matches']),\n",
    "        \"total_skills\": int(result['total_skills']),\n",
    "        \"top_matches\": [\n",
    "            {\n",
    "                'skill': match['skill'],\n",
    "                'similarity': round(float(match['similarity']), 2),\n",
    "                'match': match['match'],\n",
    "                'matched_sentence': match.get('matched_sentence', '')\n",
    "            }\n",
    "            for match in result['matches']\n",
    "        ],\n",
    "        \"job_description\": job_description\n",
    "    }\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(save_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nðŸ’¾ RÃ©sultats sauvegardÃ©s : {output_path}\")\n",
    "    print(f\"ðŸ“Š Taille : {output_path.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    print(\"\\nâœ… Analyse sÃ©mantique terminÃ©e avec succÃ¨s !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
