{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "debcf674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Projet : c:\\Users\\rober\\OneDrive\\Bureau\\PFE\n",
      "ğŸ“‚ Notebooks : c:\\Users\\rober\\OneDrive\\Bureau\\PFE\\notebooks\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Ajouter le dossier racine\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"ğŸ“ Projet : {project_root}\")\n",
    "print(f\"ğŸ“‚ Notebooks : {Path().absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51ad75c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… skills_reference.json chargÃ©\n",
      "   â€¢ Technical skills : 171\n",
      "   â€¢ Variations mappÃ©es : 45\n",
      "   â€¢ Soft skills : 39\n",
      "\n",
      "âœ… Fonctions d'extraction et normalisation dÃ©finies\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## ğŸ”§ Fonction : Extraction et Normalisation des Skills de l'Offre\n",
    "OptimisÃ© avec skills_reference.json\n",
    "\"\"\"\n",
    "\n",
    "def normalize_skill(skill: str, variations_map: dict) -> str:\n",
    "    \"\"\"\n",
    "    Normaliser un skill en utilisant le mapping de variations\n",
    "    \n",
    "    Args:\n",
    "        skill: CompÃ©tence Ã  normaliser\n",
    "        variations_map: Dict {forme_canonique: [variations]}\n",
    "        \n",
    "    Returns:\n",
    "        Forme canonique du skill\n",
    "    \"\"\"\n",
    "    skill_clean = skill.lower().strip()\n",
    "    skill_clean = skill_clean.replace('-', ' ').replace('_', ' ')\n",
    "    skill_clean = ' '.join(skill_clean.split())\n",
    "    \n",
    "    # Chercher dans le mapping de variations\n",
    "    for canonical, variations in variations_map.items():\n",
    "        if skill_clean in variations or skill_clean == canonical:\n",
    "            return canonical\n",
    "    \n",
    "    return skill_clean\n",
    "\n",
    "\n",
    "def build_variations_map(skills_db: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Construire le mapping bidirectionnel canonical â†” variations\n",
    "    \n",
    "    Args:\n",
    "        skills_db: Contenu de skills_reference.json\n",
    "        \n",
    "    Returns:\n",
    "        Dict {forme_canonique: [toutes_variations]}\n",
    "    \"\"\"\n",
    "    variations_map = {}\n",
    "    \n",
    "    # Charger depuis la section \"variations\"\n",
    "    if 'variations' in skills_db:\n",
    "        for canonical, variations_list in skills_db['variations'].items():\n",
    "            variations_map[canonical] = variations_list\n",
    "    \n",
    "    # Ajouter les skills techniques (eux-mÃªmes = forme canonique)\n",
    "    if 'technical_skills' in skills_db:\n",
    "        for skill in skills_db['technical_skills']:\n",
    "            skill_lower = skill.lower().strip()\n",
    "            if skill_lower not in variations_map:\n",
    "                variations_map[skill_lower] = [skill_lower]\n",
    "    \n",
    "    return variations_map\n",
    "\n",
    "\n",
    "def extract_job_skills_from_dict(job_dict: dict, skills_db: dict) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extraire et normaliser les skills d'une offre avec skills_reference.json\n",
    "    \n",
    "    Args:\n",
    "        job_dict: Dictionnaire avec 'requirements' et 'nice_to_have'\n",
    "        skills_db: Contenu de skills_reference.json\n",
    "        \n",
    "    Returns:\n",
    "        Liste de skills normalisÃ©s et dÃ©dupliquÃ©s\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Construire le mapping de variations\n",
    "    variations_map = build_variations_map(skills_db)\n",
    "    \n",
    "    # CrÃ©er une liste de tous les skills reconnus (formes canoniques + variations)\n",
    "    all_known_skills = set()\n",
    "    for canonical, variations in variations_map.items():\n",
    "        all_known_skills.add(canonical)\n",
    "        all_known_skills.update(variations)\n",
    "    \n",
    "    skills = []\n",
    "    \n",
    "    # 1. Requirements (prioritÃ© haute)\n",
    "    if 'requirements' in job_dict and job_dict['requirements']:\n",
    "        for req in job_dict['requirements']:\n",
    "            # Extraire mots entre parenthÃ¨ses\n",
    "            match = re.search(r'\\((.*?)\\)', req)\n",
    "            if match:\n",
    "                # Ex: \"Python (numpy, pandas)\" â†’ [\"numpy\", \"pandas\"]\n",
    "                keywords = [k.strip() for k in match.group(1).split(',')]\n",
    "                skills.extend(keywords)\n",
    "            \n",
    "            # Extraire skills connus du texte\n",
    "            req_lower = req.lower()\n",
    "            for known_skill in all_known_skills:\n",
    "                # Pattern avec boundary pour Ã©viter faux positifs\n",
    "                pattern = r'\\b' + re.escape(known_skill) + r'\\b'\n",
    "                if re.search(pattern, req_lower):\n",
    "                    skills.append(known_skill)\n",
    "    \n",
    "    # 2. Nice-to-have (prioritÃ© moyenne)\n",
    "    if 'nice_to_have' in job_dict and job_dict['nice_to_have']:\n",
    "        for nice in job_dict['nice_to_have']:\n",
    "            # MÃªme processus\n",
    "            match = re.search(r'\\((.*?)\\)', nice)\n",
    "            if match:\n",
    "                keywords = [k.strip() for k in match.group(1).split(',')]\n",
    "                skills.extend(keywords)\n",
    "            \n",
    "            nice_lower = nice.lower()\n",
    "            for known_skill in all_known_skills:\n",
    "                pattern = r'\\b' + re.escape(known_skill) + r'\\b'\n",
    "                if re.search(pattern, nice_lower):\n",
    "                    skills.append(known_skill)\n",
    "    \n",
    "    # 3. Normaliser avec le mapping\n",
    "    normalized = []\n",
    "    seen = set()\n",
    "    \n",
    "    for skill in skills:\n",
    "        if not skill or not skill.strip():\n",
    "            continue\n",
    "        \n",
    "        skill_norm = normalize_skill(skill, variations_map)\n",
    "        \n",
    "        if skill_norm not in seen:\n",
    "            normalized.append(skill_norm)\n",
    "            seen.add(skill_norm)\n",
    "    \n",
    "    print(f\"âœ… {len(normalized)} skills uniques extraits de l'offre\")\n",
    "    if normalized:\n",
    "        print(f\"   Exemples : {', '.join(normalized[:5])}\")\n",
    "    \n",
    "    return normalized\n",
    "\n",
    "\n",
    "# Charger skills_reference.json\n",
    "skills_db_path = project_root / \"data\" / \"skills_reference.json\"\n",
    "\n",
    "if not skills_db_path.exists():\n",
    "    print(f\"âŒ Fichier non trouvÃ© : {skills_db_path}\")\n",
    "    skills_db = {}\n",
    "else:\n",
    "    with open(skills_db_path, 'r', encoding='utf-8') as f:\n",
    "        skills_db = json.load(f)\n",
    "    \n",
    "    print(\"âœ… skills_reference.json chargÃ©\")\n",
    "    print(f\"   â€¢ Technical skills : {len(skills_db.get('technical_skills', []))}\")\n",
    "    print(f\"   â€¢ Variations mappÃ©es : {len(skills_db.get('variations', {}))}\")\n",
    "    print(f\"   â€¢ Soft skills : {len(skills_db.get('soft_skills', []))}\")\n",
    "\n",
    "print(\"\\nâœ… Fonctions d'extraction et normalisation dÃ©finies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca9a83b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Chargement du modÃ¨le all-mpnet-base-v2...\n",
      "â³ PremiÃ¨re utilisation : tÃ©lÃ©chargement ~420 MB (1-2 min)\n",
      "âœ… ModÃ¨le chargÃ© avec succÃ¨s\n",
      "   â€¢ Nom : all-mpnet-base-v2\n",
      "   â€¢ Dimension des vecteurs : 768\n",
      "   â€¢ Langue : Anglais (optimisÃ©)\n",
      "   â€¢ Performance : State-of-the-art pour matching sÃ©mantique\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## ğŸ¤– Chargement du modÃ¨le de vectorisation\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nğŸ” Chargement du modÃ¨le all-mpnet-base-v2...\")\n",
    "print(\"â³ PremiÃ¨re utilisation : tÃ©lÃ©chargement ~420 MB (1-2 min)\")\n",
    "\n",
    "try:\n",
    "    model = SentenceTransformer('all-mpnet-base-v2')\n",
    "    print(\"âœ… ModÃ¨le chargÃ© avec succÃ¨s\")\n",
    "    print(f\"   â€¢ Nom : all-mpnet-base-v2\")\n",
    "    print(f\"   â€¢ Dimension des vecteurs : 768\")\n",
    "    print(f\"   â€¢ Langue : Anglais (optimisÃ©)\")\n",
    "    print(f\"   â€¢ Performance : State-of-the-art pour matching sÃ©mantique\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33e511ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CompÃ©tences CV chargÃ©es : 24 skills\n",
      "\n",
      "ğŸ“‹ Exemples (10 premiÃ¨res) :\n",
      "  â€¢ .net\n",
      "  â€¢ artificial intelligence\n",
      "  â€¢ big data\n",
      "  â€¢ c\n",
      "  â€¢ c#\n",
      "  â€¢ c++\n",
      "  â€¢ data analysis\n",
      "  â€¢ data science\n",
      "  â€¢ deep learning\n",
      "  â€¢ docker\n",
      "\n",
      "âœ… Skills CV normalisÃ©s : 24 uniques\n",
      "   Exemples : dotnet, artificialintelligence, bigdata, c, csharp\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## ğŸ“„ Chargement des compÃ©tences du CV\n",
    "\"\"\"\n",
    "\n",
    "# Charger les compÃ©tences extraites prÃ©cÃ©demment\n",
    "cv_skills_path = project_root / \"outputs\" / \"extracted_skills_simple.json\"\n",
    "\n",
    "if not cv_skills_path.exists():\n",
    "    print(f\"âŒ Fichier non trouvÃ© : {cv_skills_path}\")\n",
    "    print(\"âš ï¸  ExÃ©cutez d'abord le notebook 02_skills_extraction_simple.ipynb\")\n",
    "    cv_skills = []\n",
    "else:\n",
    "    with open(cv_skills_path, 'r', encoding='utf-8') as f:\n",
    "        cv_data = json.load(f)\n",
    "    \n",
    "    cv_skills = cv_data.get('technical_skills', [])\n",
    "    \n",
    "    print(f\"âœ… CompÃ©tences CV chargÃ©es : {len(cv_skills)} skills\")\n",
    "    print(f\"\\nğŸ“‹ Exemples (10 premiÃ¨res) :\")\n",
    "    for skill in cv_skills[:10]:\n",
    "        print(f\"  â€¢ {skill}\")\n",
    "    \n",
    "    # Normaliser les skills du CV avec le mÃªme systÃ¨me\n",
    "    variations_map = build_variations_map(skills_db)\n",
    "    cv_skills_normalized = []\n",
    "    seen = set()\n",
    "    \n",
    "    for skill in cv_skills:\n",
    "        skill_norm = normalize_skill(skill, variations_map)\n",
    "        if skill_norm not in seen:\n",
    "            cv_skills_normalized.append(skill_norm)\n",
    "            seen.add(skill_norm)\n",
    "    \n",
    "    print(f\"\\nâœ… Skills CV normalisÃ©s : {len(cv_skills_normalized)} uniques\")\n",
    "    print(f\"   Exemples : {', '.join(cv_skills_normalized[:5])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "20f34c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 17 skills uniques extraits de l'offre\n",
      "   Exemples : numpy, pandas, scikitlearn, python, supervised learning\n",
      "\n",
      "============================================================\n",
      "ğŸ’¼ OFFRE D'EMPLOI\n",
      "============================================================\n",
      "Titre : Junior ML Engineer\n",
      "Entreprise : AI Startup Paris\n",
      "Localisation : Paris, France\n",
      "ExpÃ©rience : 0-2 ans\n",
      "Salaire : 35-45Kâ‚¬\n",
      "\n",
      "ğŸ”§ CompÃ©tences requises (17) :\n",
      "   1. numpy\n",
      "   2. pandas\n",
      "   3. scikitlearn\n",
      "   4. python\n",
      "   5. supervised learning\n",
      "   6. machinelearning\n",
      "   7. github\n",
      "   8. git\n",
      "   9. notions de base\n",
      "  10. docker\n",
      "  11. lecture documentation\n",
      "  12. pytorch\n",
      "  13. tensorflow\n",
      "  14. fastapi\n",
      "  15. flask\n",
      "  16. amazonwebservices\n",
      "  17. googlecloud\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## ğŸ’¼ CrÃ©ation d'une offre d'emploi de test\n",
    "\"\"\"\n",
    "\n",
    "job_offer = {\n",
    "    \"job_id\": \"job_001\",\n",
    "    \"category\": \"ml_engineer\",\n",
    "    \"title\": \"Junior ML Engineer\",\n",
    "    \"company\": \"AI Startup Paris\",\n",
    "    \"location\": \"Paris, France\",\n",
    "    \"type\": \"CDI\",\n",
    "    \"experience\": \"0-2 ans\",\n",
    "    \"salary\": \"35-45Kâ‚¬\",\n",
    "    \"description\": \"\"\"Nous recherchons un Junior ML Engineer passionnÃ© pour rejoindre notre Ã©quipe R&D.\n",
    "\n",
    "ResponsabilitÃ©s :\n",
    "- DÃ©velopper des modÃ¨les de Machine Learning (classification, rÃ©gression)\n",
    "- EntraÃ®ner et optimiser des rÃ©seaux de neurones avec PyTorch\n",
    "- DÃ©ployer des modÃ¨les en production avec Docker\n",
    "- Participer aux revues de code et Ã  l'amÃ©lioration continue\n",
    "\n",
    "Stack technique :\n",
    "- Python, PyTorch, scikit-learn\n",
    "- Docker, Git\n",
    "- FastAPI pour les APIs\n",
    "- PostgreSQL\"\"\",\n",
    "    \"requirements\": [\n",
    "        \"Python (numpy, pandas, scikit-learn)\",\n",
    "        \"Machine Learning basics (supervised learning)\",\n",
    "        \"Git et GitHub\",\n",
    "        \"Docker (notions de base)\",\n",
    "        \"Anglais technique (lecture documentation)\"\n",
    "    ],\n",
    "    \"nice_to_have\": [\n",
    "        \"PyTorch ou TensorFlow\",\n",
    "        \"FastAPI ou Flask\",\n",
    "        \"MLflow\",\n",
    "        \"AWS ou GCP\"\n",
    "    ],\n",
    "    \"posted_date\": \"2026-01-08\",\n",
    "    \"url\": \"https://example-jobs.com/1\",\n",
    "    \"remote_ok\": False,\n",
    "    \"applicants\": 99\n",
    "}\n",
    "\n",
    "# Extraire les skills de l'offre\n",
    "job_skills = extract_job_skills_from_dict(job_offer, skills_db)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ğŸ’¼ OFFRE D'EMPLOI\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Titre : {job_offer['title']}\")\n",
    "print(f\"Entreprise : {job_offer['company']}\")\n",
    "print(f\"Localisation : {job_offer['location']}\")\n",
    "print(f\"ExpÃ©rience : {job_offer['experience']}\")\n",
    "print(f\"Salaire : {job_offer['salary']}\")\n",
    "\n",
    "print(f\"\\nğŸ”§ CompÃ©tences requises ({len(job_skills)}) :\")\n",
    "for i, skill in enumerate(job_skills, 1):\n",
    "    print(f\"  {i:2d}. {skill}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da6f445b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fonction de matching Approche 4 OPTIMISÃ‰E dÃ©finie\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## ğŸ¯ Fonction de Matching : APPROCHE 4 (Job â†’ CV) - OPTIMISÃ‰E\n",
    "\"\"\"\n",
    "\n",
    "def calculate_cv_job_match_approach4(\n",
    "    cv_skills: List[str], \n",
    "    job_skills: List[str], \n",
    "    model\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    APPROCHE 4 : Skills Offre â†’ CV (VERSION OPTIMISÃ‰E)\n",
    "    \n",
    "    Pour chaque skill REQUIS par l'offre, trouver le meilleur match dans le CV.\n",
    "    Optimisation : Encoder tous les skills UNE SEULE FOIS (cache).\n",
    "    \n",
    "    Args:\n",
    "        cv_skills: Liste de compÃ©tences du CV (normalisÃ©es)\n",
    "        job_skills: Liste de compÃ©tences requises par l'offre (normalisÃ©es)\n",
    "        model: ModÃ¨le Sentence-Transformer\n",
    "        \n",
    "    Returns:\n",
    "        Dict avec score, coverage, quality et dÃ©tails\n",
    "    \"\"\"\n",
    "    if not cv_skills or not job_skills:\n",
    "        return {\n",
    "            'overall_score': 0,\n",
    "            'coverage': 0,\n",
    "            'quality': 0,\n",
    "            'covered_count': 0,\n",
    "            'total_required': 0,\n",
    "            'matches': []\n",
    "        }\n",
    "    \n",
    "    print(f\"\\nğŸ” APPROCHE 4 : Matching {len(job_skills)} skills offre â†” {len(cv_skills)} skills CV\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    # âœ… OPTIMISATION : Encoder tous les skills UNE SEULE FOIS\n",
    "    print(\"âš¡ Encodage des skills (cache)...\")\n",
    "    \n",
    "    cv_embeddings = {\n",
    "        skill: model.encode([skill.lower()], show_progress_bar=False)[0]\n",
    "        for skill in cv_skills\n",
    "    }\n",
    "    \n",
    "    job_embeddings = {\n",
    "        skill: model.encode([skill.lower()], show_progress_bar=False)[0]\n",
    "        for skill in job_skills\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ… {len(cv_embeddings)} skills CV encodÃ©s\")\n",
    "    print(f\"âœ… {len(job_embeddings)} skills offre encodÃ©s\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    matches = []\n",
    "    \n",
    "    # Pour chaque skill de l'OFFRE\n",
    "    for job_skill in job_skills:\n",
    "        job_emb = job_embeddings[job_skill]\n",
    "        \n",
    "        best_similarity = 0\n",
    "        best_cv_skill = None\n",
    "        \n",
    "        # Comparer avec CHAQUE skill du CV (rÃ©utilise le cache)\n",
    "        for cv_skill in cv_skills:\n",
    "            cv_emb = cv_embeddings[cv_skill]\n",
    "            \n",
    "            # Calcul de similaritÃ© avec embeddings prÃ©-calculÃ©s\n",
    "            similarity = cosine_similarity([job_emb], [cv_emb])[0][0] * 100\n",
    "            \n",
    "            if similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_cv_skill = cv_skill\n",
    "        \n",
    "        # DÃ©terminer le statut\n",
    "        if best_similarity >= 40:\n",
    "            status = 'covered'\n",
    "            match_level = 'high'\n",
    "            emoji = \"ğŸŸ¢\"\n",
    "        elif best_similarity >= 30:\n",
    "            status = 'partial'\n",
    "            match_level = 'medium'\n",
    "            emoji = \"ğŸŸ¡\"\n",
    "        else:\n",
    "            status = 'missing'\n",
    "            match_level = 'low'\n",
    "            emoji = \"ğŸ”´\"\n",
    "        \n",
    "        matches.append({\n",
    "            'job_skill': job_skill,\n",
    "            'cv_skill': best_cv_skill,\n",
    "            'similarity': best_similarity,\n",
    "            'status': status,\n",
    "            'match': match_level\n",
    "        })\n",
    "        \n",
    "        # Afficher en temps rÃ©el\n",
    "        print(f\"{emoji} {job_skill:30s} â†’ {best_cv_skill or 'N/A':30s} ({best_similarity:.1f}%)\")\n",
    "    \n",
    "    # Trier par similaritÃ© dÃ©croissante\n",
    "    matches = sorted(matches, key=lambda x: x['similarity'], reverse=True)\n",
    "    \n",
    "    # Calculer mÃ©triques\n",
    "    covered = [m for m in matches if m['status'] == 'covered']\n",
    "    \n",
    "    # Coverage : % de skills de l'offre couverts\n",
    "    coverage = (len(covered) / len(job_skills)) * 100 if job_skills else 0\n",
    "    \n",
    "    # Quality : QualitÃ© moyenne des matchs couverts\n",
    "    quality = sum(m['similarity'] for m in covered) / len(covered) if covered else 0\n",
    "    \n",
    "    # Score final : Moyenne pondÃ©rÃ©e\n",
    "    overall_score = (coverage * 0.5) + (quality * 0.5)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š MÃ‰TRIQUES\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Coverage : {coverage:.1f}% ({len(covered)}/{len(job_skills)} skills couverts)\")\n",
    "    print(f\"Quality  : {quality:.1f}% (qualitÃ© moyenne des matchs)\")\n",
    "    print(f\"Score    : {overall_score:.1f}%\")\n",
    "    \n",
    "    return {\n",
    "        'overall_score': overall_score,\n",
    "        'coverage': coverage,\n",
    "        'quality': quality,\n",
    "        'covered_count': len(covered),\n",
    "        'total_required': len(job_skills),\n",
    "        'matches': matches\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"âœ… Fonction de matching Approche 4 OPTIMISÃ‰E dÃ©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "195ee807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” APPROCHE 4 : Matching 17 skills offre â†” 24 skills CV\n",
      "------------------------------------------------------------\n",
      "âš¡ Encodage des skills (cache)...\n",
      "âœ… 24 skills CV encodÃ©s\n",
      "âœ… 17 skills offre encodÃ©s\n",
      "------------------------------------------------------------\n",
      "ğŸŸ¢ numpy                          â†’ numpy                          (100.0%)\n",
      "ğŸŸ¢ pandas                         â†’ pandas                         (100.0%)\n",
      "ğŸŸ¢ scikitlearn                    â†’ scikitlearn                    (100.0%)\n",
      "ğŸŸ¢ python                         â†’ python                         (100.0%)\n",
      "ğŸŸ¢ supervised learning            â†’ machinelearning                (73.3%)\n",
      "ğŸŸ¢ machinelearning                â†’ machinelearning                (100.0%)\n",
      "ğŸŸ¢ github                         â†’ git                            (78.1%)\n",
      "ğŸŸ¢ git                            â†’ git                            (100.0%)\n",
      "ğŸ”´ notions de base                â†’ datascience                    (14.6%)\n",
      "ğŸŸ¢ docker                         â†’ docker                         (100.0%)\n",
      "ğŸ”´ lecture documentation          â†’ machinelearning                (16.8%)\n",
      "ğŸŸ¢ pytorch                        â†’ jupyter                        (50.9%)\n",
      "ğŸŸ¢ tensorflow                     â†’ deeplearning                   (53.2%)\n",
      "ğŸŸ¡ fastapi                        â†’ bigdata                        (37.3%)\n",
      "ğŸŸ¢ flask                          â†’ jupyter                        (43.6%)\n",
      "ğŸ”´ amazonwebservices              â†’ nodejs                         (27.4%)\n",
      "ğŸŸ¢ googlecloud                    â†’ bigdata                        (42.4%)\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š MÃ‰TRIQUES\n",
      "============================================================\n",
      "Coverage : 76.5% (13/17 skills couverts)\n",
      "Quality  : 80.1% (qualitÃ© moyenne des matchs)\n",
      "Score    : 78.3%\n",
      "\n",
      "âœ… Matching terminÃ© avec succÃ¨s\n",
      "\n",
      "âœ… EXCELLENT MATCH - Candidat trÃ¨s qualifiÃ©\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## ğŸ”¥ Calcul du matching CV â†” Offre\n",
    "\"\"\"\n",
    "\n",
    "if cv_skills_normalized and job_skills:\n",
    "    result = calculate_cv_job_match_approach4(cv_skills_normalized, job_skills, model)\n",
    "    \n",
    "    print(\"\\nâœ… Matching terminÃ© avec succÃ¨s\")\n",
    "    \n",
    "    # Verdict\n",
    "    if result['overall_score'] >= 70:\n",
    "        verdict = \"âœ… EXCELLENT MATCH - Candidat trÃ¨s qualifiÃ©\"\n",
    "    elif result['overall_score'] >= 50:\n",
    "        verdict = \"ğŸŸ¡ BON MATCH - Candidat qualifiÃ©\"\n",
    "    else:\n",
    "        verdict = \"ğŸ”´ MATCH FAIBLE - Profil diffÃ©rent\"\n",
    "    \n",
    "    print(f\"\\n{verdict}\")\n",
    "else:\n",
    "    print(\"âŒ Impossible de calculer le matching (pas de skills)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c93d8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ¯ RÃ‰SULTATS DÃ‰TAILLÃ‰S DU MATCHING\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š SCORE GLOBAL : 78.3%\n",
      "   â€¢ Coverage : 76.5% (13/17 skills)\n",
      "   â€¢ Quality  : 80.1%\n",
      "\n",
      "ğŸŸ¢ COMPÃ‰TENCES COUVERTES (13) :\n",
      "----------------------------------------------------------------------\n",
      " 1. numpy                     â†’ numpy                     (100.0%)\n",
      " 2. pandas                    â†’ pandas                    (100.0%)\n",
      " 3. python                    â†’ python                    (100.0%)\n",
      " 4. git                       â†’ git                       (100.0%)\n",
      " 5. machinelearning           â†’ machinelearning           (100.0%)\n",
      " 6. docker                    â†’ docker                    (100.0%)\n",
      " 7. scikitlearn               â†’ scikitlearn               (100.0%)\n",
      " 8. github                    â†’ git                       (78.1%)\n",
      " 9. supervised learning       â†’ machinelearning           (73.3%)\n",
      "10. tensorflow                â†’ deeplearning              (53.2%)\n",
      "11. pytorch                   â†’ jupyter                   (50.9%)\n",
      "12. flask                     â†’ jupyter                   (43.6%)\n",
      "13. googlecloud               â†’ bigdata                   (42.4%)\n",
      "\n",
      "ğŸ”´ COMPÃ‰TENCES MANQUANTES (3) :\n",
      "----------------------------------------------------------------------\n",
      " 1. amazonwebservices              (meilleur match : nodejs 27.4%)\n",
      " 2. lecture documentation          (meilleur match : machinelearning 16.8%)\n",
      " 3. notions de base                (meilleur match : datascience 14.6%)\n",
      "\n",
      "ğŸŸ¡ COMPÃ‰TENCES PARTIELLES (1) :\n",
      "----------------------------------------------------------------------\n",
      " 1. fastapi                   â†’ bigdata                   (37.3%)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## ğŸ“‹ RÃ©sultats dÃ©taillÃ©s du matching\n",
    "\"\"\"\n",
    "\n",
    "if 'result' in locals() and result['matches']:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ¯ RÃ‰SULTATS DÃ‰TAILLÃ‰S DU MATCHING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š SCORE GLOBAL : {result['overall_score']:.1f}%\")\n",
    "    print(f\"   â€¢ Coverage : {result['coverage']:.1f}% ({result['covered_count']}/{result['total_required']} skills)\")\n",
    "    print(f\"   â€¢ Quality  : {result['quality']:.1f}%\")\n",
    "    \n",
    "    # Top matches\n",
    "    print(f\"\\nğŸŸ¢ COMPÃ‰TENCES COUVERTES ({result['covered_count']}) :\")\n",
    "    print(\"-\"*70)\n",
    "    covered_matches = [m for m in result['matches'] if m['status'] == 'covered']\n",
    "    for i, match in enumerate(covered_matches, 1):\n",
    "        print(f\"{i:2d}. {match['job_skill']:25s} â†’ {match['cv_skill']:25s} ({match['similarity']:.1f}%)\")\n",
    "    \n",
    "    # Skills manquants\n",
    "    missing_matches = [m for m in result['matches'] if m['status'] == 'missing']\n",
    "    if missing_matches:\n",
    "        print(f\"\\nğŸ”´ COMPÃ‰TENCES MANQUANTES ({len(missing_matches)}) :\")\n",
    "        print(\"-\"*70)\n",
    "        for i, match in enumerate(missing_matches, 1):\n",
    "            best = f\"(meilleur match : {match['cv_skill']} {match['similarity']:.1f}%)\" if match['cv_skill'] else \"\"\n",
    "            print(f\"{i:2d}. {match['job_skill']:30s} {best}\")\n",
    "    \n",
    "    # Skills partiels\n",
    "    partial_matches = [m for m in result['matches'] if m['status'] == 'partial']\n",
    "    if partial_matches:\n",
    "        print(f\"\\nğŸŸ¡ COMPÃ‰TENCES PARTIELLES ({len(partial_matches)}) :\")\n",
    "        print(\"-\"*70)\n",
    "        for i, match in enumerate(partial_matches, 1):\n",
    "            print(f\"{i:2d}. {match['job_skill']:25s} â†’ {match['cv_skill']:25s} ({match['similarity']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dda648b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "âš–ï¸  COMPARAISON DES APPROCHES\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š RÃ‰SULTATS :\n",
      "----------------------------------------------------------------------\n",
      "MÃ©thode                                       Score      MÃ©trique\n",
      "----------------------------------------------------------------------\n",
      "APPROCHE 2 (CV â†’ Job - Ancienne)                38.1%   Moyenne tous skills CV\n",
      "APPROCHE 4 (Job â†’ CV - Nouvelle)                78.3%   Coverage + Quality\n",
      "  â†³ Coverage : 76.5%\n",
      "  â†³ Quality  : 80.1%\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "ğŸ’¡ ANALYSE :\n",
      "   DiffÃ©rence : +40.2 points\n",
      "   âœ… Approche 4 plus juste : Focus sur les compÃ©tences requises\n",
      "\n",
      "ğŸ“ˆ RECOMMANDATION :\n",
      "   L'Approche 4 est plus Ã©quitable car elle se concentre sur les\n",
      "   compÃ©tences REQUISES par l'offre, sans pÃ©naliser les CVs avec\n",
      "   des compÃ©tences diversifiÃ©es.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## âš–ï¸ Comparaison : Approche 2 (CV â†’ Job) vs Approche 4 (Job â†’ CV)\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âš–ï¸  COMPARAISON DES APPROCHES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# APPROCHE 2 : CV Skills â†’ Job Description (ancien)\n",
    "def calculate_approach2(cv_skills_norm, job_description, model):\n",
    "    \"\"\"Ancienne mÃ©thode : moyenne de tous les skills du CV\"\"\"\n",
    "    job_sentences = [s.strip() for s in job_description.split('\\n') if s.strip() and len(s.strip()) > 10]\n",
    "    \n",
    "    if not job_sentences:\n",
    "        return 0\n",
    "    \n",
    "    job_embeddings = model.encode(job_sentences, show_progress_bar=False)\n",
    "    \n",
    "    scores = []\n",
    "    for skill in cv_skills_norm:\n",
    "        skill_embedding = model.encode([skill.lower()], show_progress_bar=False)\n",
    "        similarities = cosine_similarity(skill_embedding, job_embeddings)[0]\n",
    "        max_sim = max(similarities) * 100\n",
    "        scores.append(max_sim)\n",
    "    \n",
    "    return sum(scores) / len(scores) if scores else 0\n",
    "\n",
    "# Calculer avec Approche 2\n",
    "score_approach2 = calculate_approach2(cv_skills_normalized, job_offer['description'], model)\n",
    "\n",
    "print(f\"\\nğŸ“Š RÃ‰SULTATS :\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'MÃ©thode':<45} {'Score':<10} {'MÃ©trique'}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'APPROCHE 2 (CV â†’ Job - Ancienne)':<45} {score_approach2:>6.1f}%   Moyenne tous skills CV\")\n",
    "print(f\"{'APPROCHE 4 (Job â†’ CV - Nouvelle)':<45} {result['overall_score']:>6.1f}%   Coverage + Quality\")\n",
    "print(f\"  â†³ Coverage : {result['coverage']:.1f}%\")\n",
    "print(f\"  â†³ Quality  : {result['quality']:.1f}%\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Analyse\n",
    "diff = result['overall_score'] - score_approach2\n",
    "print(f\"\\nğŸ’¡ ANALYSE :\")\n",
    "print(f\"   DiffÃ©rence : {diff:+.1f} points\")\n",
    "\n",
    "if abs(diff) < 5:\n",
    "    print(\"   âœ… Scores cohÃ©rents : Le CV est bien ciblÃ© pour cette offre\")\n",
    "elif diff > 0:\n",
    "    print(\"   âœ… Approche 4 plus juste : Focus sur les compÃ©tences requises\")\n",
    "else:\n",
    "    print(\"   âš ï¸  Approche 2 plus gÃ©nÃ©reuse : Valorise la diversitÃ© des compÃ©tences\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ RECOMMANDATION :\")\n",
    "print(\"   L'Approche 4 est plus Ã©quitable car elle se concentre sur les\")\n",
    "print(\"   compÃ©tences REQUISES par l'offre, sans pÃ©naliser les CVs avec\")\n",
    "print(\"   des compÃ©tences diversifiÃ©es.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "221d81b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ§ª TEST D'Ã‰QUITÃ‰ : SPÃ‰CIALISTE vs GÃ‰NÃ‰RALISTE vs PARTIEL\n",
      "======================================================================\n",
      "\n",
      "ğŸ‘¤ Candidat A (SpÃ©cialiste) : 5 skills\n",
      "   python, pytorch, scikitlearn, docker, git\n",
      "\n",
      "ğŸ‘¤ Candidat B (GÃ©nÃ©raliste) : 10 skills\n",
      "   python, pytorch, scikitlearn, docker, git + 5 autres hors sujet\n",
      "\n",
      "ğŸ‘¤ Candidat C (Partiel) : 4 skills\n",
      "   python, pandas, excel, powerpoint\n",
      "\n",
      "ğŸ” Calcul des scores...\n",
      "\n",
      "ğŸ” APPROCHE 4 : Matching 17 skills offre â†” 5 skills CV\n",
      "------------------------------------------------------------\n",
      "âš¡ Encodage des skills (cache)...\n",
      "âœ… 5 skills CV encodÃ©s\n",
      "âœ… 17 skills offre encodÃ©s\n",
      "------------------------------------------------------------\n",
      "ğŸŸ¢ numpy                          â†’ python                         (56.8%)\n",
      "ğŸŸ¢ pandas                         â†’ python                         (50.6%)\n",
      "ğŸŸ¢ scikitlearn                    â†’ scikitlearn                    (100.0%)\n",
      "ğŸŸ¢ python                         â†’ python                         (100.0%)\n",
      "ğŸŸ¢ supervised learning            â†’ scikitlearn                    (47.1%)\n",
      "ğŸŸ¢ machinelearning                â†’ scikitlearn                    (48.3%)\n",
      "ğŸŸ¢ github                         â†’ git                            (78.1%)\n",
      "ğŸŸ¢ git                            â†’ git                            (100.0%)\n",
      "ğŸ”´ notions de base                â†’ docker                         (12.0%)\n",
      "ğŸŸ¢ docker                         â†’ docker                         (100.0%)\n",
      "ğŸ”´ lecture documentation          â†’ python                         (9.6%)\n",
      "ğŸŸ¢ pytorch                        â†’ pytorch                        (100.0%)\n",
      "ğŸŸ¢ tensorflow                     â†’ pytorch                        (63.4%)\n",
      "ğŸ”´ fastapi                        â†’ pytorch                        (28.5%)\n",
      "ğŸŸ¡ flask                          â†’ python                         (37.6%)\n",
      "ğŸ”´ amazonwebservices              â†’ scikitlearn                    (17.9%)\n",
      "ğŸŸ¡ googlecloud                    â†’ git                            (34.3%)\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š MÃ‰TRIQUES\n",
      "============================================================\n",
      "Coverage : 64.7% (11/17 skills couverts)\n",
      "Quality  : 76.8% (qualitÃ© moyenne des matchs)\n",
      "Score    : 70.7%\n",
      "\n",
      "ğŸ” APPROCHE 4 : Matching 17 skills offre â†” 10 skills CV\n",
      "------------------------------------------------------------\n",
      "âš¡ Encodage des skills (cache)...\n",
      "âœ… 10 skills CV encodÃ©s\n",
      "âœ… 17 skills offre encodÃ©s\n",
      "------------------------------------------------------------\n",
      "ğŸŸ¢ numpy                          â†’ python                         (56.8%)\n",
      "ğŸŸ¢ pandas                         â†’ python                         (50.6%)\n",
      "ğŸŸ¢ scikitlearn                    â†’ scikitlearn                    (100.0%)\n",
      "ğŸŸ¢ python                         â†’ python                         (100.0%)\n",
      "ğŸŸ¢ supervised learning            â†’ scikitlearn                    (47.1%)\n",
      "ğŸŸ¢ machinelearning                â†’ scikitlearn                    (48.3%)\n",
      "ğŸŸ¢ github                         â†’ git                            (78.1%)\n",
      "ğŸŸ¢ git                            â†’ git                            (100.0%)\n",
      "ğŸ”´ notions de base                â†’ docker                         (12.0%)\n",
      "ğŸŸ¢ docker                         â†’ docker                         (100.0%)\n",
      "ğŸŸ¢ lecture documentation          â†’ powerpoint                     (43.9%)\n",
      "ğŸŸ¢ pytorch                        â†’ pytorch                        (100.0%)\n",
      "ğŸŸ¢ tensorflow                     â†’ pytorch                        (63.4%)\n",
      "ğŸ”´ fastapi                        â†’ pytorch                        (28.5%)\n",
      "ğŸŸ¡ flask                          â†’ python                         (37.6%)\n",
      "ğŸ”´ amazonwebservices              â†’ wordpress                      (25.3%)\n",
      "ğŸŸ¢ googlecloud                    â†’ wordpress                      (42.3%)\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š MÃ‰TRIQUES\n",
      "============================================================\n",
      "Coverage : 76.5% (13/17 skills couverts)\n",
      "Quality  : 71.6% (qualitÃ© moyenne des matchs)\n",
      "Score    : 74.0%\n",
      "\n",
      "ğŸ” APPROCHE 4 : Matching 17 skills offre â†” 4 skills CV\n",
      "------------------------------------------------------------\n",
      "âš¡ Encodage des skills (cache)...\n",
      "âœ… 4 skills CV encodÃ©s\n",
      "âœ… 17 skills offre encodÃ©s\n",
      "------------------------------------------------------------\n",
      "ğŸŸ¢ numpy                          â†’ python                         (56.8%)\n",
      "ğŸŸ¢ pandas                         â†’ pandas                         (100.0%)\n",
      "ğŸŸ¢ scikitlearn                    â†’ python                         (46.1%)\n",
      "ğŸŸ¢ python                         â†’ python                         (100.0%)\n",
      "ğŸŸ¡ supervised learning            â†’ python                         (32.7%)\n",
      "ğŸŸ¡ machinelearning                â†’ python                         (36.6%)\n",
      "ğŸ”´ github                         â†’ python                         (29.9%)\n",
      "ğŸŸ¡ git                            â†’ python                         (35.0%)\n",
      "ğŸ”´ notions de base                â†’ python                         (5.8%)\n",
      "ğŸ”´ docker                         â†’ python                         (18.1%)\n",
      "ğŸŸ¢ lecture documentation          â†’ powerpoint                     (43.9%)\n",
      "ğŸŸ¢ pytorch                        â†’ python                         (43.8%)\n",
      "ğŸŸ¢ tensorflow                     â†’ python                         (40.8%)\n",
      "ğŸ”´ fastapi                        â†’ pandas                         (26.3%)\n",
      "ğŸŸ¡ flask                          â†’ python                         (37.6%)\n",
      "ğŸ”´ amazonwebservices              â†’ python                         (12.9%)\n",
      "ğŸ”´ googlecloud                    â†’ excel                          (21.0%)\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š MÃ‰TRIQUES\n",
      "============================================================\n",
      "Coverage : 41.2% (7/17 skills couverts)\n",
      "Quality  : 61.6% (qualitÃ© moyenne des matchs)\n",
      "Score    : 51.4%\n",
      "\n",
      "================================================================================\n",
      "ğŸ“Š RÃ‰SULTATS COMPARATIFS\n",
      "================================================================================\n",
      "Candidat             Score        Coverage     Quality      Verdict\n",
      "--------------------------------------------------------------------------------\n",
      "A (SpÃ©cialiste)        70.7%        64.7%        76.8%      âœ… Excellent\n",
      "B (GÃ©nÃ©raliste)        74.0%        76.5%        71.6%      âœ… Excellent\n",
      "C (Partiel)            51.4%        41.2%        61.6%      ğŸŸ¡ Bon\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ğŸ’¡ CONCLUSION :\n",
      "   â€¢ A et B ont des scores similaires malgrÃ© 5 vs 10 skills âœ…\n",
      "   â€¢ C a un score plus faible car couvre moins de requirements âœ…\n",
      "   â€¢ L'Approche 4 ne pÃ©nalise PAS la diversitÃ© des compÃ©tences ! ğŸ¯\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "## ğŸ§ª Test d'Ã©quitÃ© : 3 profils diffÃ©rents\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ§ª TEST D'Ã‰QUITÃ‰ : SPÃ‰CIALISTE vs GÃ‰NÃ‰RALISTE vs PARTIEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Candidat A : SpÃ©cialiste (5 skills ciblÃ©s)\n",
    "cv_A = [\"python\", \"pytorch\", \"scikitlearn\", \"docker\", \"git\"]\n",
    "\n",
    "# Candidat B : GÃ©nÃ©raliste (mÃªme 5 skills + 5 autres hors sujet)\n",
    "cv_B = [\"python\", \"pytorch\", \"scikitlearn\", \"docker\", \"git\", \n",
    "        \"excel\", \"powerpoint\", \"photoshop\", \"wordpress\", \"management\"]\n",
    "\n",
    "# Candidat C : Partiel (seulement 2 skills pertinents)\n",
    "cv_C = [\"python\", \"pandas\", \"excel\", \"powerpoint\"]\n",
    "\n",
    "print(f\"\\nğŸ‘¤ Candidat A (SpÃ©cialiste) : {len(cv_A)} skills\")\n",
    "print(f\"   {', '.join(cv_A)}\")\n",
    "\n",
    "print(f\"\\nğŸ‘¤ Candidat B (GÃ©nÃ©raliste) : {len(cv_B)} skills\")\n",
    "print(f\"   {', '.join(cv_B[:5])} + {len(cv_B)-5} autres hors sujet\")\n",
    "\n",
    "print(f\"\\nğŸ‘¤ Candidat C (Partiel) : {len(cv_C)} skills\")\n",
    "print(f\"   {', '.join(cv_C)}\")\n",
    "\n",
    "# Calculer scores\n",
    "print(\"\\nğŸ” Calcul des scores...\")\n",
    "result_A = calculate_cv_job_match_approach4(cv_A, job_skills, model)\n",
    "result_B = calculate_cv_job_match_approach4(cv_B, job_skills, model)\n",
    "result_C = calculate_cv_job_match_approach4(cv_C, job_skills, model)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ“Š RÃ‰SULTATS COMPARATIFS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Candidat':<20} {'Score':<12} {'Coverage':<12} {'Quality':<12} {'Verdict'}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for name, res in [(\"A (SpÃ©cialiste)\", result_A), (\"B (GÃ©nÃ©raliste)\", result_B), (\"C (Partiel)\", result_C)]:\n",
    "    if res['overall_score'] >= 70:\n",
    "        verdict = \"âœ… Excellent\"\n",
    "    elif res['overall_score'] >= 50:\n",
    "        verdict = \"ğŸŸ¡ Bon\"\n",
    "    else:\n",
    "        verdict = \"ğŸ”´ Insuffisant\"\n",
    "    \n",
    "    print(f\"{name:<20} {res['overall_score']:>6.1f}%      {res['coverage']:>6.1f}%      {res['quality']:>6.1f}%      {verdict}\")\n",
    "\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\nğŸ’¡ CONCLUSION :\")\n",
    "print(f\"   â€¢ A et B ont des scores similaires malgrÃ© 5 vs 10 skills âœ…\")\n",
    "print(f\"   â€¢ C a un score plus faible car couvre moins de requirements âœ…\")\n",
    "print(f\"   â€¢ L'Approche 4 ne pÃ©nalise PAS la diversitÃ© des compÃ©tences ! ğŸ¯\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
