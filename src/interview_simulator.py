"""
üé§ Simulateur d'Entretien IA
G√©n√©ration de questions personnalis√©es et √©valuation des r√©ponses avec Groq (Llama 3.1 70B)
"""

import os
from typing import List, Dict, Optional
from groq import Groq
import json
from dotenv import load_dotenv

# Charger les variables d'environnement depuis .env
load_dotenv()


class InterviewSimulator:
    """
    Simulateur d'entretien bas√© sur Groq (Llama 3.1 70B Versatile)
    """

    def __init__(self, api_key: Optional[str] = None):
        """
        Initialiser le simulateur

        Args:
            api_key: Cl√© API Groq (ou None pour utiliser variable d'environnement)
        """
        self.api_key = api_key or os.getenv("GROQ_API_KEY")

        if not self.api_key:
            raise ValueError(
                "‚ùå Cl√© API Groq manquante.\n"
                "D√©finissez GROQ_API_KEY dans vos variables d'environnement ou passez api_key en param√®tre.\n"
                "Obtenez une cl√© gratuite sur : https://console.groq.com/")

        self.client = Groq(api_key=self.api_key)
        self.model = "llama-3.3-70b-versatile"

        print(f"‚úÖ InterviewSimulator initialis√© avec {self.model}")

    def generate_questions(
        self,
        cv_skills: List[str],
        job_title: str,
        job_description: str,
        job_requirements: List[str],
        num_questions: int = 8
    ) -> Dict:
        """
        G√©n√©rer des questions d'entretien personnalis√©es

        Args:
            cv_skills: Comp√©tences extraites du CV
            job_title: Titre du poste
            job_description: Description du poste
            job_requirements: Comp√©tences requises
            num_questions: Nombre de questions (d√©faut: 8)

        Returns:
            Dict avec questions RH et techniques
        """
        # Limiter les comp√©tences pour le prompt (√©viter overflow)
        cv_skills_str = ', '.join(cv_skills[:20])
        requirements_str = ', '.join(job_requirements[:15])

        # Construire le prompt
        prompt = f"""Tu es un recruteur technique exp√©riment√©. Tu dois pr√©parer un entretien pour un candidat junior.

**PROFIL CANDIDAT:**
Comp√©tences: {cv_skills_str}

**POSTE CIBL√â:**
Titre: {job_title}
Description: {job_description[:300]}...
Comp√©tences requises: {requirements_str}

**CONSIGNES:**
G√©n√®re exactement {num_questions} questions d'entretien (50% RH + 50% techniques) au format JSON strict.

Format JSON attendu:
{{
  "rh_questions": [
    {{"id": 1, "question": "Parlez-moi de vous et de votre parcours.", "type": "pr√©sentation"}},
    {{"id": 2, "question": "Pourquoi ce poste vous int√©resse ?", "type": "motivation"}},
    {{"id": 3, "question": "D√©crivez une situation o√π vous avez travaill√© en √©quipe.", "type": "soft_skills"}},
    {{"id": 4, "question": "Parlez-moi d'un projet dont vous √™tes fier.", "type": "projet"}}
  ],
  "technical_questions": [
    {{"id": 5, "question": "Comment utilisez-vous Python dans vos projets ?", "type": "comp√©tence_technique", "skill": "Python"}},
    {{"id": 6, "question": "Expliquez comment vous structureriez une API REST.", "type": "architecture", "skill": "API"}},
    {{"id": 7, "question": "D√©crivez votre exp√©rience avec Docker.", "type": "outil", "skill": "Docker"}},
    {{"id": 8, "question": "Comment d√©bugguez-vous un bug en production ?", "type": "r√©solution_probl√®me", "skill": "Debugging"}}
  ]
}}

**R√àGLES IMPORTANTES:**
- Questions RH adapt√©es √† un profil junior (0-2 ans d'exp√©rience)
- Questions techniques bas√©es sur les comp√©tences du CV ET du poste
- Pas de questions system design complexe pour un junior
- Chaque question technique doit mentionner une comp√©tence sp√©cifique dans "skill"
- Retourne UNIQUEMENT le JSON, aucun texte avant ou apr√®s
- Le JSON doit √™tre valide (pas de virgule finale, guillemets corrects)
"""

        try:
            # Appel API Groq
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "Tu es un assistant RH expert. Tu r√©ponds UNIQUEMENT en JSON valide, sans markdown."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.7,
                max_tokens=2000,
                top_p=0.9
            )

            # Extraire le JSON
            content = response.choices[0].message.content.strip()

            # Nettoyer le JSON (enlever markdown si pr√©sent)
            if content.startswith("```json"):
                content = content.replace(
                    "```json", "").replace(
                    "```", "").strip()
            elif content.startswith("```"):
                content = content.replace("```", "").strip()

            # Parser le JSON
            questions = json.loads(content)

            # Validation
            if "rh_questions" not in questions or "technical_questions" not in questions:
                raise ValueError(
                    "Format JSON invalide : cl√©s 'rh_questions' ou 'technical_questions' manquantes")

            if not isinstance(
                    questions['rh_questions'],
                    list) or not isinstance(
                    questions['technical_questions'],
                    list):
                raise ValueError(
                    "Format JSON invalide : 'rh_questions' et 'technical_questions' doivent √™tre des listes")

            print(f"‚úÖ {len(questions['rh_questions'])} questions RH g√©n√©r√©es")
            print(
                f"‚úÖ {len(questions['technical_questions'])} questions techniques g√©n√©r√©es")

            return questions

        except json.JSONDecodeError as e:
            print(f"‚ùå Erreur parsing JSON : {e}")
            print(f"R√©ponse brute (300 premiers caract√®res) : {content[:300]}")
            raise ValueError(f"Le LLM n'a pas retourn√© un JSON valide : {e}")
        except Exception as e:
            print(f"‚ùå Erreur g√©n√©ration questions : {e}")
            raise

    def evaluate_answer(
        self,
        question: str,
        answer: str,
        question_type: str,
        target_skill: Optional[str] = None
    ) -> Dict:
        """
        √âvaluer la r√©ponse d'un candidat

        Args:
            question: Question pos√©e
            answer: R√©ponse du candidat
            question_type: Type de question (pr√©sentation, motivation, technique, etc.)
            target_skill: Comp√©tence cibl√©e (pour questions techniques)

        Returns:
            Dict avec score, feedback et points forts/faibles
        """
        # Construire le contexte
        skill_context = f"\nComp√©tence √©valu√©e: {target_skill}" if target_skill else ""

        # Prompt d'√©valuation
        prompt = f"""Tu es un √©valuateur d'entretien technique bienveillant mais rigoureux. √âvalue cette r√©ponse.

**QUESTION:**
{question}

**TYPE DE QUESTION:** {question_type}{skill_context}

**R√âPONSE DU CANDIDAT:**
{answer}

**CONSIGNES:**
√âvalue la r√©ponse sur une √©chelle de 0 √† 100 et donne un feedback constructif.

Format JSON attendu:
{{
  "score": 75,
  "evaluation": "R√©ponse claire et structur√©e. Le candidat d√©montre une bonne compr√©hension...",
  "points_forts": [
    "Exemples concrets mentionn√©s",
    "Bonne structure de r√©ponse",
    "D√©montre l'autonomie"
  ],
  "points_amelioration": [
    "Pourrait ajouter des m√©triques chiffr√©es",
    "Manque de d√©tails techniques"
  ],
  "recommandations": [
    "Pr√©parer 2-3 exemples avec r√©sultats mesurables",
    "Approfondir les aspects techniques"
  ]
}}

**CRIT√àRES D'√âVALUATION:**
- Clart√© et structure (0-20 points)
- Pertinence et exemples concrets (0-30 points)
- Profondeur technique si applicable (0-30 points)
- Communication et soft skills (0-20 points)

**R√àGLES:**
- Sois bienveillant mais honn√™te
- Pour un profil junior, valorise l'apprentissage et la motivation
- Un score < 50 = r√©ponse insuffisante
- Un score 50-70 = correct mais √† am√©liorer
- Un score 70-85 = bonne r√©ponse
- Un score > 85 = excellente r√©ponse
- Retourne UNIQUEMENT le JSON, sans markdown
"""

        try:
            # Appel API
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "Tu es un √©valuateur RH expert. Tu r√©ponds UNIQUEMENT en JSON valide."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,  # Plus d√©terministe pour l'√©valuation
                max_tokens=1200
            )

            content = response.choices[0].message.content.strip()

            # Nettoyer JSON
            if content.startswith("```json"):
                content = content.replace(
                    "```json", "").replace(
                    "```", "").strip()
            elif content.startswith("```"):
                content = content.replace("```", "").strip()

            evaluation = json.loads(content)

            # Validation
            required_keys = [
                "score",
                "evaluation",
                "points_forts",
                "points_amelioration"]
            missing_keys = [
                key for key in required_keys if key not in evaluation]
            if missing_keys:
                raise ValueError(
                    f"Cl√©s manquantes dans le JSON : {missing_keys}")

            # Normaliser le score (0-100)
            evaluation["score"] = max(0, min(100, float(evaluation["score"])))

            # S'assurer que les listes sont bien des listes
            if not isinstance(evaluation["points_forts"], list):
                evaluation["points_forts"] = [str(evaluation["points_forts"])]
            if not isinstance(evaluation["points_amelioration"], list):
                evaluation["points_amelioration"] = [
                    str(evaluation["points_amelioration"])]

            # Ajouter recommandations si manquantes
            if "recommandations" not in evaluation:
                evaluation["recommandations"] = [
                    "Continuer √† pratiquer", "Pr√©parer des exemples concrets"]

            print(f"‚úÖ R√©ponse √©valu√©e : {evaluation['score']:.0f}/100")

            return evaluation

        except json.JSONDecodeError as e:
            print(f"‚ùå Erreur parsing JSON : {e}")
            print(f"R√©ponse brute : {content[:300]}")
            raise ValueError(f"Le LLM n'a pas retourn√© un JSON valide : {e}")
        except Exception as e:
            print(f"‚ùå Erreur √©valuation : {e}")
            raise

    def generate_final_feedback(
        self,
        evaluations: List[Dict],
        job_title: str
    ) -> Dict:
        """
        G√©n√©rer un feedback global sur la simulation

        Args:
            evaluations: Liste des √©valuations individuelles
            job_title: Titre du poste

        Returns:
            Dict avec feedback global et recommandations
        """
        if not evaluations:
            return {
                "global_score": 0,
                "decision": "Aucune √©valuation",
                "synthese": "Aucune r√©ponse n'a √©t√© √©valu√©e.",
                "competences_validees": [],
                "axes_progression": [],
                "prochaines_etapes": ["Commencer la simulation d'entretien"]
            }

        # Calculer statistiques
        scores = [eval_data["score"] for eval_data in evaluations]
        avg_score = sum(scores) / len(scores)

        # Agr√©ger points forts/faibles
        all_strengths = []
        all_improvements = []

        for eval_data in evaluations:
            all_strengths.extend(eval_data.get("points_forts", []))
            all_improvements.extend(eval_data.get("points_amelioration", []))

        # Prompt pour feedback global
        prompt = f"""Tu es un recruteur senior. G√©n√®re un feedback global sur cette simulation d'entretien.

**POSTE CIBL√â:** {job_title}

**R√âSULTATS DE LA SIMULATION:**
- Score moyen: {avg_score:.1f}/100
- Nombre de questions: {len(evaluations)}
- Scores individuels: {', '.join(f'{s:.0f}' for s in scores)}

**POINTS FORTS IDENTIFI√âS:**
{chr(10).join(f"- {s}" for s in list(set(all_strengths))[:8])}

**POINTS D'AM√âLIORATION:**
{chr(10).join(f"- {i}" for i in list(set(all_improvements))[:8])}

**CONSIGNES:**
G√©n√®re un feedback global bienveillant mais constructif.

Format JSON attendu:
{{
  "global_score": {avg_score:.1f},
  "decision": "√Ä retravailler",
  "synthese": "En 2-3 phrases, r√©sume la performance globale du candidat.",
  "competences_validees": ["Comp√©tence 1", "Comp√©tence 2", "..."],
  "axes_progression": ["Axe 1", "Axe 2", "..."],
  "prochaines_etapes": ["√âtape 1", "√âtape 2", "..."]
}}

**R√àGLES:**
- decision: "√Ä retravailler" si score < 50, "Prometteur" si 50-75, "Excellent" si > 75
- synthese: 2-3 phrases sur la performance globale
- competences_validees: 3-5 points forts principaux
- axes_progression: 3-5 axes d'am√©lioration concrets
- prochaines_etapes: 3-4 actions concr√®tes √† faire
- Ton bienveillant et encourageant
- Retourne UNIQUEMENT le JSON
"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Tu es un coach carri√®re expert. R√©ponds en JSON valide."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=1000
            )

            content = response.choices[0].message.content.strip()

            if content.startswith("```json"):
                content = content.replace(
                    "```json", "").replace(
                    "```", "").strip()
            elif content.startswith("```"):
                content = content.replace("```", "").strip()

            feedback = json.loads(content)

            print(f"‚úÖ Feedback global g√©n√©r√©")

            return feedback

        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur g√©n√©ration feedback global : {e}")
            # Fallback avec feedback basique
            if avg_score < 50:
                decision = "√Ä retravailler"
            elif avg_score < 75:
                decision = "Prometteur"
            else:
                decision = "Excellent"

            return {
                "global_score": round(avg_score, 1),
                "decision": decision,
                "synthese": f"Vous avez obtenu un score moyen de {avg_score:.1f}/100 sur {len(evaluations)} questions. {'Continuez √† vous entra√Æner.' if avg_score < 70 else 'Bonne performance globale !'}",
                "competences_validees": list(set(all_strengths[:5])),
                "axes_progression": list(set(all_improvements[:5])),
                "prochaines_etapes": [
                    "Pratiquer les questions d'entretien r√©guli√®rement",
                    "Pr√©parer 3-5 exemples concrets de projets",
                    "Travailler la structure STAR (Situation, T√¢che, Action, R√©sultat)"
                ]
            }


# ============================================================================
# SINGLETON POUR API
# ============================================================================

_interview_simulator = None


def get_interview_simulator() -> InterviewSimulator:
    """Obtenir le simulateur (singleton)"""
    global _interview_simulator
    if _interview_simulator is None:
        _interview_simulator = InterviewSimulator()
    return _interview_simulator
