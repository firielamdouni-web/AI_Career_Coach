version: '3.8'

# ============================================================================
# DÉFINITION DES SERVICES (CONTENEURS)
# ============================================================================
services:

  # --------------------------------------------------------------------------
  # SERVICE 1 : BASE DE DONNÉES POSTGRESQL
  # --------------------------------------------------------------------------
  postgres:
    image: postgres:15-alpine
    container_name: ai-career-coach-db
    restart: unless-stopped
    
    environment:
      POSTGRES_USER: coach_user
      POSTGRES_PASSWORD: coach_password_2024
      POSTGRES_DB: ai_career_coach
      PGDATA: /var/lib/postgresql/data/pgdata
    
    volumes:
      - postgres_data:/var/lib/postgresql/data
      # Initialiser la BDD au premier démarrage
      - ../scripts/init_db.sql:/docker-entrypoint-initdb.d/init_db.sql
    
    ports:
      - "5432:5432"
    
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U coach_user -d ai_career_coach"]
      interval: 10s
      timeout: 5s
      retries: 5
    
    networks:
      - ai-coach-network

  # --------------------------------------------------------------------------
  # SERVICE 2 : API FASTAPI
  # --------------------------------------------------------------------------
  api:
    image: ai-career-coach-api:latest
    container_name: ai-career-coach-api
    restart: unless-stopped
    
    deploy:
      resources:
        limits:
          memory: 8G
        reservations:
          memory: 4G 

    environment:
      # Configuration API
      API_ENV: production
      API_PORT: 8000
      
      # Configuration PostgreSQL
      DATABASE_URL: postgresql://coach_user:coach_password_2024@postgres:5432/ai_career_coach
      
      # Configuration Groq (pour simulation entretien)
      GROQ_API_KEY: ${GROQ_API_KEY}
      MLFLOW_TRACKING_URI: http://mlflow:5000
      
    volumes:
      # ✅ MODIFICATION : Monter TOUT le code source pour éviter rebuild
      - ../../src:/app/src                 # Code Python modifiable à chaud
      - ../../data:/app/data               # Données (jobs, skills)
      - ../../models:/app/models            # Modèles ML (si besoin)
      - ../../outputs:/app/outputs         # Résultats
      - ../../.env:/app/.env                  # Variables d'environnement
    
    ports:
      - "8000:8000"
    
    depends_on:
      postgres:
        condition: service_healthy
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 300s
    
    networks:
      - ai-coach-network
    
    # ✅ NOUVEAU : Commande avec --reload pour auto-restart
    command: uvicorn src.api:app --host 0.0.0.0 --port 8000 --reload

  # --------------------------------------------------------------------------
  # SERVICE 3 : STREAMLIT FRONTEND
  # --------------------------------------------------------------------------
  streamlit:
    image: ai-career-coach-streamlit:latest
    container_name: ai-career-coach-frontend
    restart: unless-stopped
    
    environment:
      RUNNING_IN_DOCKER: "true"
      # URL de l'API (nom du service Docker)
      API_BASE_URL: http://ai-career-coach-api:8000
    
    volumes:
      # Monter uniquement les fichiers Streamlit
      - ../../app.py:/app/app.py
      - ../../pages:/app/pages
    
    ports:
      - "8501:8501"
    
    depends_on:
      - api
    
    networks:
      - ai-coach-network

  # --------------------------------------------------------------------------
  # SERVICE 4 : MLFLOW TRACKING SERVER
  # --------------------------------------------------------------------------
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.10.2
    container_name: ai-career-coach-mlflow
    restart: unless-stopped
    
    environment:
      # Configuration MLflow
      MLFLOW_BACKEND_STORE_URI: sqlite:///mlflow/mlflow.db
      MLFLOW_DEFAULT_ARTIFACT_ROOT: /mlflow/artifacts
    
    volumes:
      # Stockage persistant pour runs et modèles
      - mlflow_data:/mlflow
      # Partage des modèles avec l'API
      - ../../mlops:/app/mlops
      - ../../models:/app/models
    
    ports:
      - "5000:5000"
    
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:///mlflow/mlflow.db
      --default-artifact-root /mlflow/artifacts
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    networks:
      - ai-coach-network

# ============================================================================
# DÉFINITION DES VOLUMES (STOCKAGE PERSISTANT)
# ============================================================================
volumes:
  postgres_data:
    driver: local
  mlflow_data:             
    driver: local 
# ============================================================================
# DÉFINITION DES RÉSEAUX (COMMUNICATION INTER-CONTENEURS)
# ============================================================================
networks:
  ai-coach-network:
    driver: bridge