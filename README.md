# ğŸ¯ AI Career Coach - SystÃ¨me Intelligent de Matching CV â†” Offres d'Emploi

## ğŸ“– Description du Projet

**AI Career Coach** est un systÃ¨me intelligent d'aide Ã  l'emploi destinÃ© aux **profils juniors en Data Science et ML Engineering**. Le projet combine **NLP**, **embeddings sÃ©mantiques**, **machine learning** et **recherche vectorielle** pour proposer des recommandations d'emploi personnalisÃ©es basÃ©es sur l'analyse automatique de CV.

###  Objectifs Principaux

1. **Extraction automatique** des compÃ©tences techniques et soft skills depuis un CV PDF
2. **Matching sÃ©mantique** entre profil candidat et offres d'emploi
3. **Scoring intelligent** basÃ© sur la couverture et la qualitÃ© des compÃ©tences
4. **Recommandations personnalisÃ©es** avec explication des forces et faiblesses
5. **Simulation d'entretiens** avec gÃ©nÃ©ration de questions contextuelles
6. **MLOps pipeline** avec tracking des expÃ©riences et dÃ©ploiement de modÃ¨les

## ğŸ“ Structure du projet

```
AI_Career_Coach/
â”‚
â”œâ”€â”€ ğŸ“ data/                               # DonnÃ©es et artifacts
â”‚   â”œâ”€â”€ ğŸ“ jobs/                           # Offres d'emploi et embeddings
â”‚   â”‚   â””â”€â”€ jobs_dataset.json              # 25 offres d'emploi (Data Science/ML)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ resume_fit_job/                   # Dataset CV-Job
â”‚   â”‚   â”œâ”€â”€ ğŸ“ processed/                    # DonnÃ©es nettoyÃ©es
â”‚   â”‚   â”‚   â””â”€â”€ v2_dataset_resume_job_fit_processed.xlsx  # Dataset nettoyÃ© (4,524 samples)
â”‚   â”‚   â””â”€â”€ ğŸ“ raw/                          # DonnÃ©es brutes
â”‚   â”‚       â””â”€â”€ huggingface_resume_job_fit_RAW.xlsx  # Dataset brut (6,241 samples)
â”‚   â”‚
â”‚   â”œâ”€â”€ skills_reference.json                # CompÃ©tences techniques + soft skills
â”‚   â””â”€â”€ RESUME_*.pdf                         # CVs de test
â”‚
â”œâ”€â”€ ğŸ“ db/ 
â”‚   â”œâ”€â”€ ğŸ“ init/                         
â”‚       â””â”€â”€ init_db.sql                     # SchÃ©ma PostgreSQL
â”‚
â”œâ”€â”€ ğŸ“ docker/                             # Dockerfiles
â”‚   â”œâ”€â”€ api.Dockerfile                      # Image Docker API FastAPI
â”‚   â””â”€â”€ streamlit.Dockerfile                # Image Docker Streamlit
â”‚
â”œâ”€â”€ ğŸ“ mlops/                                # Pipeline MLOps
â”‚   â”œâ”€â”€ train_and_log.py                     # EntraÃ®nement + tracking MLflow
â”‚   â”œâ”€â”€ register_model.py                    # Enregistrement Model Registry
â”‚   â””â”€â”€ serve_model.py                       # Test de prÃ©diction
â”‚
â”œâ”€â”€ ğŸ“ models/                               # ModÃ¨les entraÃ®nÃ©s (metadata uniquement)
â”‚   â””â”€â”€ classifier_clean_metadata.json       # MÃ©tadonnÃ©es du modÃ¨le XGBoost
â”‚
â”œâ”€â”€ ğŸ“ notebooks/                            # Notebooks de dÃ©veloppement
â”‚   â”œâ”€â”€ 01_cv_parser.ipynb                   # Parsing de CV PDF
â”‚   â”œâ”€â”€ 02_skills_extraction_simple.ipynb    # Extraction de compÃ©tences CV
â”‚   â”œâ”€â”€ 03_extraction_skills_job_offers.ipynb # Extraction de compÃ©tences jobs
â”‚   â”œâ”€â”€ 03_semantic_matching.ipynb            # Tests de matching sÃ©mantique
â”‚   â”œâ”€â”€ 04_job_generation.ipynb              # GÃ©nÃ©ration du dataset d'offres
â”‚   â”œâ”€â”€ 05_job_recommendation.ipynb          # SystÃ¨me de recommandation
â”‚   â”œâ”€â”€ 06_faiss_indexing.ipynb              # Base vectorielle
â”‚   â”œâ”€â”€ 07_interview_simulation.ipynb        # Simulation d'entretiens
â”‚   â”œâ”€â”€ 08_exploration_dataset_RAW.ipynb     # Exploration dataset brute
â”‚   â””â”€â”€ 09_ml_model_training.ipynb           # EntraÃ®nement modÃ¨le ML (XGBoost, 70% accuracy)
â”‚
â”œâ”€â”€ ğŸ“ src/                                   # Code source principal
â”‚   â”œâ”€â”€ api.py                               # API FastAPI (endpoints REST)
â”‚   â”œâ”€â”€ cv_parser.py                         # Parser CV (PyPDF2 + pdfplumber)
â”‚   â”œâ”€â”€ skills_extractor.py                  # Extraction compÃ©tences (spaCy + regex)
â”‚   â”œâ”€â”€ job_matcher.py                       # Matching sÃ©mantique (SentenceTransformer)
â”‚   â”œâ”€â”€ vector_store.py                      # Recherche vectorielle (FAISS)
â”‚   â”œâ”€â”€ database.py                          # Gestion PostgreSQL (SQLAlchemy)
â”‚   â”œâ”€â”€ interview_simulator.py               # GÃ©nÃ©ration questions d'entretien
â”‚   â””â”€â”€ compute_features_from_huggingface.py # Calcul features ML
â”‚
â”œâ”€â”€ ğŸ“ pages/                               # Pages Streamlit
â”‚   â””â”€â”€ 1_Interview_Simulation.py           # Page simulation entretien
â”‚
â”œâ”€â”€ ğŸ“ tests/                                 # Tests unitaires
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“ requirements/ 
â”‚   â”œâ”€â”€ api.txt                                  # DÃ©pendances API (FastAPI, Groq...)
â”‚   â”œâ”€â”€ frontend.txt                             # DÃ©pendances Streamlit
â”‚   â””â”€â”€ base.txt                                 # DÃ©pendances communs
â”‚
â”œâ”€â”€ app.py                                    # Dashboard Streamlit (frontend)
â”œâ”€â”€ requirements.txt                          # DÃ©pendances Python
â”œâ”€â”€ docker-compose.yml                        # Orchestration 4 services Docker
â”œâ”€â”€ .env.example                              # Template variables d'environnement
â”œâ”€â”€ .dockerignore                             # Fichiers exclus du build
â”œâ”€â”€ .gitignore                                
â””â”€â”€ README.md                                
```

## ğŸš€ Quick Start

### **Option 1 : DÃ©marrage avec Docker (RecommandÃ©)**

```bash
# 1. Cloner le repo
git clone https://github.com/firielamdouni-web/AI_Career_Coach/tree/Firiel
cd AI_Career_Coach

# 2. Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env avec vos valeurs et ajouter votre GROQ_API_KEY

# 3. Lancer tous les services (PostgreSQL + API + Streamlit + MLflow)
docker-compose up -d

# 4. VÃ©rifier que tout est UP
docker-compose ps

# 5. EntraÃ®ner et enregistrer le modÃ¨le
docker-compose exec api python mlops/train_and_log.py
docker-compose exec api python mlops/register_model.py

# 6. AccÃ©der aux interfaces
# - API Swagger : http://localhost:8000/docs
# - Streamlit UI : http://localhost:8501
# - MLflow UI : http://localhost:5000
```

**VÃ©rification rapide :**

```bash
# Health check API
curl http://localhost:8000/health

# Stats du systÃ¨me
curl http://localhost:8000/api/v1/stats

# Tester une recommandation
curl -X POST "http://localhost:8000/api/v1/recommend-jobs" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@data/CV_exemple.pdf" \
  -F "top_k=5"
```

**ArrÃªter les services :**

```bash
cd deployment/docker
docker-compose down           # ArrÃªter sans supprimer les donnÃ©es
docker-compose down -v        # ArrÃªter et supprimer les volumes (reset complet)
```

---

### **Option 2 : DÃ©marrage en local (DÃ©veloppement)**

```bash
# 1. Cloner le repo
git clone https://github.com/firielamdouni-web/AI_Career_Coach/tree/Firiel
cd AI_Career_Coach

# 2. CrÃ©er l'environnement virtuel
python -m venv env
source env/bin/activate  # (ou env\Scripts\activate sur Windows)

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. TÃ©lÃ©charger le modÃ¨le spaCy
python -m spacy download en_core_news_lg

# 5. Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env et ajouter votre GROQ_API_KEY

# 6. (Optionnel) EntraÃ®ner le modÃ¨le ML et tracker avec MLflow
python mlops/train_and_log.py
python mlops/register_model.py

# 7. Lancer MLflow UI (dans un terminal sÃ©parÃ©)
mlflow ui --backend-store-uri file:./mlops/mlflow_tracking --port 5000
# AccÃ©der Ã  MLflow UI : http://localhost:5000

# 8. Lancer l'API FastAPI (dans un autre terminal)
uvicorn src.api:app --reload --port 8000
# Documentation interactive : http://localhost:8000/docs

# 9. Lancer le dashboard Streamlit (dans un troisiÃ¨me terminal)
streamlit run app.py
# Interface utilisateur : http://localhost:8501
```

---

## ğŸ¯ **Architecture du SystÃ¨me**

### **ğŸ³ Architecture Docker (4-tiers)**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     UTILISATEUR / NAVIGATEUR                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     STREAMLIT FRONTEND (Port 8501)      â”‚
        â”‚     â€¢ Upload CV                         â”‚
        â”‚     â€¢ Affichage recommandations         â”‚
        â”‚     â€¢ Simulation d'entretiens           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“ HTTP POST
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     FASTAPI BACKEND (Port 8000)         â”‚
        â”‚     â€¢ 8 endpoints REST                  â”‚
        â”‚     â€¢ Extraction skills                 â”‚
        â”‚     â€¢ Matching sÃ©mantique               â”‚
        â”‚     â€¢ Scoring intelligent               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â†“                           â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  POSTGRESQL (5432)    â”‚   â”‚  MLFLOW SERVER (5000) â”‚
    â”‚  â€¢ Stockage CVs       â”‚   â”‚  â€¢ Model Registry     â”‚
    â”‚  â€¢ Historique matchs  â”‚   â”‚  â€¢ Tracking runs      â”‚
    â”‚  â€¢ Logs candidats     â”‚   â”‚  â€¢ Artifacts ML       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **ğŸ“¡ Endpoints API Disponibles**

| MÃ©thode | Endpoint | Description |
|---------|----------|-------------|
| `GET` | `/health` | Statut de l'API |
| `GET` | `/api/v1/stats` | Statistiques globales (jobs, skills) |
| `POST` | `/api/v1/extract-skills` | Extraire compÃ©tences d'un CV PDF |
| `POST` | `/api/v1/recommend-jobs` | Recommander des jobs (TOP-K) |
| `GET` | `/api/v1/jobs` | Lister tous les jobs disponibles |
| `GET` | `/api/v1/jobs/{job_id}` | DÃ©tails d'un job spÃ©cifique |
| `POST` | `/api/v1/simulate-interview` | GÃ©nÃ©rer questions d'entretien |
| `POST` | `/api/v1/evaluate-answer` | Ã‰valuer une rÃ©ponse candidat |
| `POST` | `/api/v1/search` | Recherche sÃ©mantique de jobs |
| `POST` | `/api/v1/match` | Matching CV â†” Job spÃ©cifique |

---

## ğŸ¯ **Pipeline de Matching CV â†” Jobs**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. UPLOAD CV (Streamlit)                                       â”‚
â”‚     â€¢ Utilisateur upload CV PDF via interface                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. PARSING (cv_parser.py)                                      â”‚
â”‚     â€¢ pdfplumber                                                â”‚
â”‚     â€¢ Extraction texte brut (~2000 caractÃ¨res)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. EXTRACTION SKILLS (skills_extractor.py)                     â”‚
â”‚     â€¢ spaCy (fr_core_news_lg)                                   â”‚
â”‚     â€¢ Pattern matching sur 1250 skills                           â”‚
â”‚     â€¢ RÃ©sultat : ["python", "pandas", "numpy", ...]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. PRÃ‰-FILTRAGE FAISS (vector_store.py) [OPTIONNEL]            â”‚
â”‚     â€¢ Embedding CV avec SentenceTransformer                     â”‚
â”‚     â€¢ Recherche Top-50 dans index FAISS                         â”‚
â”‚     â€¢ Temps : ~0.5s vs 2.5s (brute force)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. SCORING DÃ‰TAILLÃ‰ (job_matcher.py)                           â”‚
â”‚     â€¢ Calcul similaritÃ© CV â†” Job (cosinus)                      â”‚
â”‚     â€¢ Score = (Coverage Ã— 0.5) + (Quality Ã— 0.5)                â”‚
â”‚     â€¢ Coverage : Skills couverts / Skills requis                â”‚
â”‚     â€¢ Quality : Moyenne similaritÃ©s sÃ©mantiques                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. TRI & FILTRAGE (api.py)                                     â”‚
â”‚     â€¢ Tri par score dÃ©croissant                                 â”‚
â”‚     â€¢ Filtrage score minimum (dÃ©faut: 40%)                      â”‚
â”‚     â€¢ Limitation Top-K (dÃ©faut: 25)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. AFFICHAGE (app.py)                                          â”‚
â”‚     â€¢ Cards avec score + compÃ©tences matchÃ©es/manquantes        â”‚
â”‚     â€¢ Filtres interactifs (remote, expÃ©rience, score)           â”‚
â”‚     â€¢ Graphiques de rÃ©partition                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª **Tests et Validation**

### **Tester l'API avec cURL**

```bash
# 1. Extraction de compÃ©tences
curl -X POST "http://localhost:8000/api/v1/extract-skills" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@data/CV_exemple.pdf"

# 2. Recommandation de jobs (TOP 5)
curl -X POST "http://localhost:8000/api/v1/recommend-jobs" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@data/CV_exemple.pdf" \
  -F "top_k=5"

# 3. Recherche sÃ©mantique
curl -X POST "http://localhost:8000/api/v1/search" \
  -H "Content-Type: application/json" \
  -d '{"query": "Machine learning engineer with Python", "top_k": 5}'

# 4. Simulation d'entretien
curl -X POST "http://localhost:8000/api/v1/simulate-interview" \
  -H "Content-Type: application/json" \
  -d '{
    "job_title": "Data Scientist",
    "cv_skills": ["Python", "Machine Learning", "TensorFlow"],
    "num_questions": 3
  }'
```

### **Script de test complet**

```bash
# CrÃ©er le script
cat > test_api.sh << 'EOF'
#!/bin/bash
echo "ğŸ§ª TEST COMPLET DE L'API"
echo "========================"

CV_PATH="data/CV_exemple.pdf"

echo "1ï¸âƒ£ Health Check..."
curl -s http://localhost:8000/health | jq .

echo "2ï¸âƒ£ Statistiques..."
curl -s http://localhost:8000/api/v1/stats | jq .

echo "3ï¸âƒ£ Recommandations TOP 3..."
curl -s -X POST "http://localhost:8000/api/v1/recommend-jobs" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@$CV_PATH" \
  -F "top_k=3" | jq .

echo "âœ… TESTS TERMINÃ‰S"
EOF

# Rendre exÃ©cutable
chmod +x test_api.sh

# Lancer
./test_api.sh
```

---

## ğŸ¯ **ModÃ¨le ML EntraÃ®nÃ©**

### **CaractÃ©ristiques du ModÃ¨le**

- **Type** : XGBoost Classifier
- **Classes** : 3 (No Fit, Partial Fit, Perfect Fit)
- **Features** : 15 (coverage, quality, similarities, etc.)
- **Performance** : ~70% accuracy (Test Set)
- **Dataset** : 4,524 samples (nettoyÃ© depuis 6,241 bruts)
- **Tracking** : MLflow (expÃ©riences + Model Registry)

### **Features UtilisÃ©es (15)**

```python
[
    'job_title_similarity',
    'description_similarity', 
    'requirements_similarity',
    'responsibilities_similarity',
    'matching_skills_count',
    'missing_skills_count',
    'skills_coverage',
    'avg_skill_similarity',
    'max_skill_similarity',
    'min_skill_similarity',
    'cv_job_cosine_similarity',
    'quality_score',
    'has_remote',
    'experience_level',
    'company_type'
]
```

### **EntraÃ®ner et Tracker le ModÃ¨le**

```bash
# EntraÃ®ner le modÃ¨le et logger dans MLflow
python mlops/train_and_log.py

# Enregistrer dans le Model Registry
python mlops/register_model.py

# Tester une prÃ©diction
python mlops/serve_model.py

# Consulter les runs dans MLflow UI
mlflow ui --backend-store-uri file:./mlops/mlflow_tracking --port 5000
# Ouvrir http://localhost:5000
```

---

## ğŸ› ï¸ **Technologies UtilisÃ©es**

### **Backend**
- **FastAPI** : API REST moderne et performante
- **PostgreSQL** : Base de donnÃ©es relationnelle
- **SQLAlchemy** : ORM Python

### **NLP & ML**
- **spaCy** : Extraction de compÃ©tences (en_core_news_lg)
- **SentenceTransformers** : Embeddings sÃ©mantiques (all-mpnet-base-v2)
- **FAISS** : Recherche vectorielle ultra-rapide
- **XGBoost** : Classification des matchs CV-Job
- **Groq** : LLM pour simulation d'entretiens

### **MLOps**
- **MLflow** : Tracking expÃ©riences + Model Registry
- **Docker** : Containerisation 4-tiers
- **Docker Compose** : Orchestration multi-conteneurs

### **Frontend**
- **Streamlit** : Dashboard interactif
- **Plotly** : Visualisations graphiques

### **Parsing PDF**
- **pdfplumber** : Extraction texte 

---

## ğŸ“Š **Performances**

| MÃ©trique | Valeur |
|----------|--------|
| **Jobs disponibles** | 25 offres (Data Science/ML) |
| **Skills trackÃ©s** | 171 compÃ©tences techniques |
| **Temps parsing CV** | ~2-3 secondes |
| **Temps matching** | ~0.1s/job (2.5s pour 25 jobs) |
| **Temps total pipeline** | ~7-10 secondes |
| **Accuracy modÃ¨le ML** | 70% (test set) |
| **Index FAISS** | 768 dimensions (SentenceTransformer) |

---

## ğŸŒ **URLs ClÃ©s (Mode Docker)**

| Service | URL | Description |
|---------|-----|-------------|
| **API Swagger** | http://localhost:8000/docs | Documentation interactive API |
| **API Health** | http://localhost:8000/health | Statut de l'API |
| **Streamlit** | http://localhost:8501 | Interface utilisateur |
| **MLflow UI** | http://localhost:5000 | Tracking des modÃ¨les |
| **PostgreSQL** | localhost:5432 | Base de donnÃ©es (psql uniquement) |


---


[![CI/CD Pipeline](https://github.com/firielamdouni-web/AI_Career_Coach/actions/workflows/ci.yml/badge.svg)](https://github.com/firielamdouni-web/AI_Career_Coach/actions/workflows/ci.yml)
[![Python 3.10](https://img.shields.io/badge/python-3.10-blue.svg)](https://www.python.org/downloads/release/python-310/)
[![Tests](https://img.shields.io/badge/tests-149%20passed-brightgreen.svg)]() 